{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2dc6813e",
   "metadata": {},
   "source": [
    "Artificial Intelligence Technology and Application\n",
    "Deep Learning\n",
    "Lab Guide\n",
    "Student Version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9f46d6",
   "metadata": {},
   "source": [
    "# Deep Learning Lab Guide\n",
    "\n",
    "<b> Nama &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;  : </b> Daniel Morantha <br>\n",
    "<b> Student ID  &nbsp; &nbsp; : </b> 149294373101-310 <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50318c4d",
   "metadata": {},
   "source": [
    "### 1.2.1.1 Importing TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7526195",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e832025",
   "metadata": {},
   "source": [
    "Step  &nbsp; &nbsp;  1 tf.constant() <br>\n",
    "**tf.constant(value, dtype=None, shape=None, name='Const', verify_shape=False):** <br>\n",
    " <ul>\n",
    "    <li><b>value:</b> value</li>\n",
    "    <li><b>dtype:</b> data type</li>\n",
    "    <li><b>shape:</b> tensor type</li>\n",
    "    <li><b>name:</b> constant name</li>\n",
    "    <li><b>verify_shape:</b> Boolean value, used to verify the shape of a value. The default value is \n",
    "False. If verify_shape is set to True, the system checks whether the shape of a value \n",
    "is consistent with the shape. If they are inconsistent, the system reports an error.</li>\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e48ff30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[1., 2.],\n",
       "       [3., 4.]], dtype=float32)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const_a = tf.constant([[1, 2, 3, 4]],shape=[2,2], dtype=tf.float32) # Create a 2x2 matrix with \n",
    "const_a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5c2ba4",
   "metadata": {},
   "source": [
    "Step 2 &nbsp; tf.zeros(), tf.zeros_like(), tf.ones(), and tf.ones_like()\n",
    "Usages of  <b>tf.ones()</b> and <b>tf.ones_like()</b> are similar to those of <b>tf.zeros() </b> and <b>tf.zeros_like().</b> <br> \n",
    "Therefore, the following describes only the usages of tf.ones() and tf.ones_like().\n",
    "Create a constant with the value <b> 0. tf.zeros(shape, dtype=tf.float32, name=None): </b>\n",
    "<ul>\n",
    "    <li><b>shape</b>: tensor shape.</li>\n",
    "    <li><b>dtype: </b>data type</li>\n",
    "    <li><b>name: </b>specifies the template name</li>\n",
    "    \n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c49b8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros_b = tf.zeros(shape=[2, 3], dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bf66be",
   "metadata": {},
   "source": [
    "Create a tensor whose value is 0 based on the input tensor, with its shape being the same \n",
    "as that of the input tensor:\n",
    "tf.zeros_like(input_tensor, dtype=None, name=None, optimize=True):\n",
    "<ul>\n",
    "    <li><b>input_tensor:</b>tensor.</li>\n",
    "    <li><b>dtype: </b>data type</li>\n",
    "    <li><b>name: </b>tensor name</li>\n",
    "    <li><b>optimize:</b>indicates whether optimization is enabled.</li>\n",
    "    \n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba765216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0.],\n",
       "       [0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros_like_c = tf.zeros_like(const_a)\n",
    "#View generated data.\n",
    "zeros_like_c.numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee7d48b",
   "metadata": {},
   "source": [
    "tf.fill() <br>\n",
    "Create a tensor and fill it with a specific value. tf.fill(dims, value, name=None):\n",
    "<ul>\n",
    "    <li><b>dims: </b>tensor shape, which is the same as shape above.</li>\n",
    "    <li><b>value:</b>tensor value</li>\n",
    "    <li><b>name: </b>tensor name</li>\n",
    "   \n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9851bcd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8, 8, 8],\n",
       "       [8, 8, 8],\n",
       "       [8, 8, 8]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fill_d = tf.fill([3,3], 8) # Buat matriks 2x3 dengan semua nilai menjadi 8.\n",
    "#Lihat data\n",
    "fill_d.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a7248f",
   "metadata": {},
   "source": [
    "tf.random <br>\n",
    "This module is used to generate a tensor with a specific distribution. Common methods in this \n",
    "module include <b>tf.random.uniform()</b>, <b>tf.random.normal()</b>, and <b>tf.random.shuffle().</b> The \n",
    "following describes how to use <b>tf.random.normal().</b><br>\n",
    "Create a tensor that conforms to a normal distribution.<br>\n",
    "tf.random.normal(shape, mean=0.0, stddev=1.0, dtype=tf.float32,seed=None, name=None): <br>\n",
    "\n",
    "<ul>\n",
    "    <li><b>shape: </b> data shape</li>\n",
    "    <li><b>mean:</b>mean value with a Gaussian distribution</li>\n",
    "    <li><b>stddev: </b>standard deviation with a Gaussian distribution</li>\n",
    "    <li><b>dtype</b> data shape</li>\n",
    "    <li><b>seed:</b> random seed</li>\n",
    "    <li><b>name:</b> tensor name</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11cbfbb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.8113182 ,  1.4845988 ,  0.06532937, -2.4427042 ,  0.0992484 ],\n",
       "       [ 0.5912243 ,  0.59282297, -2.1229296 , -0.72289723, -0.05627038],\n",
       "       [ 0.6435448 , -0.26432407,  1.8566332 ,  0.5678417 , -0.3828359 ],\n",
       "       [-1.4853433 ,  1.2617711 , -0.02530608, -0.2646297 ,  1.5328138 ],\n",
       "       [-1.7429771 , -0.43789294, -0.56601   ,  0.32066926,  1.132831  ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_e = tf.random.normal([5,5],mean=0,stddev=1.0, seed = 1)\n",
    "#Lihat data yg dibuat.\n",
    "random_e.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d90052",
   "metadata": {},
   "source": [
    "Step 5 Create a list object by using NumPy, and then convert the list object into a tensor by using \n",
    "<b>tf.convert_to_tensor.</b> <br>\n",
    "This method can convert a given value into a tensor. <b>tf.convert_to_tensor</b> can be used to \n",
    "convert a Python data type into a tensor data type available to TensorFlow.<br>\n",
    "tf.convert_to_tensor(value,dtype=None,dtype_hint=None,name=None):\n",
    "<ul>\n",
    "    <li><b>value: </b> value to be converted</li>\n",
    "    <li><b>dtype:</b>data type of the tensor</li>\n",
    "    <li><b>dtype_hint:</b>optional element type for the returned tensor, used when <b>dtype</b> is \n",
    "        set to <b>None</b>. In some cases, a caller may not consider dtype when calling <b>tf.convert_to_tensor</b>. \n",
    "        Therefore, <b>dtype_hint</b> can be used as a preference.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59fc57ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Bangun list.\n",
    "list_f = [1,2,3,4,5,6]\n",
    "# lihat list\n",
    "type(list_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dcfb76dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6,), dtype=float32, numpy=array([1., 2., 3., 4., 5., 6.], dtype=float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_f = tf.convert_to_tensor(list_f, dtype=tf.float32)\n",
    "tensor_f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edb758a",
   "metadata": {},
   "source": [
    "1.2.1.1.2 Creating a Variable Tensor <br>\n",
    "In TensorFlow, variables are operated using the <b>tf.Variable</b> class. <b>tf.Variable</b> indicates a \n",
    "tensor. The value of <b>tf.Variable</b> can be changed by running an arithmetic operation on \n",
    "<b>tf.Variable</b>. Variable values can be read and changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20b221de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[1., 1., 1.],\n",
       "       [1., 1., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Bangun variabel. Hanya nilai awal yang perlu diberikan.\n",
    "var_1 = tf.Variable(tf.ones([2,3]))\n",
    "var_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f4cf010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of the variable var_1: tf.Tensor(\n",
      "[[1. 1. 1.]\n",
      " [1. 1. 1.]], shape=(2, 3), dtype=float32)\n",
      "Value of the variable var_1 after the assignment: tf.Tensor(\n",
      "[[1. 2. 3.]\n",
      " [4. 5. 6.]], shape=(2, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#Membaca nilai dari variable\n",
    "print(\"Value of the variable var_1:\",var_1.read_value())\n",
    "# Menetapkan nilai variabel\n",
    "var_value_1=[[1,2,3],[4,5,6]] \n",
    "var_1.assign(var_value_1)\n",
    "print(\"Value of the variable var_1 after the assignment:\",var_1.read_value())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c189a86e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[2., 3., 4.],\n",
       "       [5., 6., 7.]], dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Penambahan nilai variable\n",
    "var_1.assign_add(tf.ones([2,3]))\n",
    "var_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d035ef2d",
   "metadata": {},
   "source": [
    "## Tensor Slicing and Indexing <br>\n",
    "## 1.2.1.3.1 Slicing <br>\n",
    "Tensor slicing methods include: <br>\n",
    "\n",
    "<ul>\n",
    "    <li><b>[start: End]: </b>extracts a data slice from the start position to the end position of the \n",
    "tensor.</li>\n",
    "    <li><b>[start:end:step] or [::step]:</b>extracts a data slice at an interval of step from the start \n",
    "position to the end position of the tensor.</li>\n",
    "    <li><b>[::-1]:</b>slices data from the last element</li>\n",
    "    <li><b>'...':</b>indicates a data slice of any length.</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "644583e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 100, 100, 3), dtype=float32, numpy=\n",
       "array([[[[ 1.4562087 , -1.4419875 , -0.0783527 ],\n",
       "         [ 0.27075505, -2.3132937 , -1.4670018 ],\n",
       "         [-0.25047097, -1.0218505 ,  0.9714081 ],\n",
       "         ...,\n",
       "         [ 1.0086595 , -0.52435637,  1.3170794 ],\n",
       "         [ 0.957892  ,  0.9369246 ,  0.5940449 ],\n",
       "         [-0.98134524,  0.5684921 , -1.4435033 ]],\n",
       "\n",
       "        [[-0.54834515,  0.57787573, -0.69312245],\n",
       "         [-0.04144788, -0.01168209, -0.33810532],\n",
       "         [-0.85379535, -0.49939635,  1.2713962 ],\n",
       "         ...,\n",
       "         [-0.4496524 ,  1.6964539 ,  0.5302422 ],\n",
       "         [-0.32005426, -0.64427924, -2.070247  ],\n",
       "         [-1.6325626 ,  2.5323832 ,  2.351591  ]],\n",
       "\n",
       "        [[ 1.4742026 , -0.4427584 ,  1.3805368 ],\n",
       "         [-0.8890921 , -0.35605747, -1.2094271 ],\n",
       "         [-0.4607863 ,  0.42250872,  1.340159  ],\n",
       "         ...,\n",
       "         [-0.60539794, -0.9810849 , -0.7736408 ],\n",
       "         [-1.5524977 ,  0.4837724 , -1.6826777 ],\n",
       "         [-0.9810144 ,  0.07747748,  0.96968454]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-2.4536188 , -0.7396818 ,  1.2800527 ],\n",
       "         [-1.5141575 , -1.2606256 , -1.1759346 ],\n",
       "         [ 0.04149139,  0.32904503,  0.3360036 ],\n",
       "         ...,\n",
       "         [-0.5229448 ,  0.9758602 ,  1.2034825 ],\n",
       "         [ 0.73482186,  0.88683814, -0.26354563],\n",
       "         [ 0.9032049 ,  2.7317035 , -0.49074164]],\n",
       "\n",
       "        [[-0.09721033, -0.02016292, -1.4593234 ],\n",
       "         [ 0.4018314 , -0.5323158 ,  0.13737352],\n",
       "         [-0.43385702,  0.07326435,  0.37679964],\n",
       "         ...,\n",
       "         [-0.6510627 , -0.2100805 ,  1.2958064 ],\n",
       "         [ 0.52936983, -0.06314103, -1.5466092 ],\n",
       "         [ 1.4888753 ,  0.884846  ,  0.09351158]],\n",
       "\n",
       "        [[-1.2838606 , -0.44548783, -1.6666826 ],\n",
       "         [-0.28075293,  0.0091745 , -1.584549  ],\n",
       "         [-1.9191386 , -0.7787316 ,  0.82842547],\n",
       "         ...,\n",
       "         [-2.3215394 ,  1.4999858 ,  0.42965567],\n",
       "         [ 0.6500103 ,  0.11333774, -1.2496572 ],\n",
       "         [-1.3060138 ,  0.4483606 , -0.16933577]]],\n",
       "\n",
       "\n",
       "       [[[-1.7066896 ,  1.4898326 ,  1.078528  ],\n",
       "         [-1.0937972 , -1.4391749 , -0.05441549],\n",
       "         [-0.03208932, -1.2319435 ,  0.11344619],\n",
       "         ...,\n",
       "         [ 0.77300835,  0.0755583 , -0.39939067],\n",
       "         [ 0.9936557 ,  1.4485638 ,  0.667712  ],\n",
       "         [-2.3010478 ,  0.23390372,  0.49109066]],\n",
       "\n",
       "        [[ 0.8656338 ,  0.88571155, -1.7513474 ],\n",
       "         [-0.51496935, -0.16807957,  1.5247873 ],\n",
       "         [-0.98722047, -0.82758063, -0.4402495 ],\n",
       "         ...,\n",
       "         [ 0.54505396, -0.04586942,  1.9019759 ],\n",
       "         [ 0.5951845 , -0.6126047 ,  0.07897622],\n",
       "         [-0.77430934, -2.1448634 ,  1.2670382 ]],\n",
       "\n",
       "        [[ 1.9834658 ,  0.8584483 , -0.16268064],\n",
       "         [ 1.1441928 ,  0.11874662, -0.31415635],\n",
       "         [ 0.7854686 , -1.2267128 ,  1.7966653 ],\n",
       "         ...,\n",
       "         [-0.03814313, -0.73275435,  0.46984968],\n",
       "         [ 2.1732945 , -1.2719408 , -1.6309074 ],\n",
       "         [-1.0988913 ,  1.2687498 , -0.6717013 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.3851376 , -0.841486  , -1.6923465 ],\n",
       "         [-2.0379348 , -0.27640057, -0.65749156],\n",
       "         [-1.053849  ,  1.3897476 , -0.76481444],\n",
       "         ...,\n",
       "         [ 0.22525978,  0.736188  , -1.9164859 ],\n",
       "         [-0.6167677 , -1.2439477 , -0.05458681],\n",
       "         [ 0.3183658 ,  0.7209911 , -1.7651904 ]],\n",
       "\n",
       "        [[-0.33534473,  1.123207  , -0.4705633 ],\n",
       "         [ 1.9338088 , -1.4979734 , -1.0288324 ],\n",
       "         [-2.1232493 , -0.17211029,  0.5542008 ],\n",
       "         ...,\n",
       "         [-1.170167  , -1.2147437 ,  0.31513438],\n",
       "         [-0.58993065, -0.27416706,  1.4123936 ],\n",
       "         [-0.32437798, -0.15596837,  0.54083633]],\n",
       "\n",
       "        [[-1.3853852 ,  0.20503455,  0.04193249],\n",
       "         [-0.15172525,  0.40373498,  1.0168786 ],\n",
       "         [-0.14487897,  0.14349094, -2.2299035 ],\n",
       "         ...,\n",
       "         [ 0.5927507 ,  1.8509623 , -0.6380369 ],\n",
       "         [-1.2425569 , -1.3272448 ,  0.03280028],\n",
       "         [-1.0473673 , -0.6058104 ,  0.84692395]]],\n",
       "\n",
       "\n",
       "       [[[ 0.58937025, -0.2530481 , -1.179859  ],\n",
       "         [ 0.20970912, -0.43773502,  0.54661274],\n",
       "         [-0.4556593 , -1.0287808 , -1.1576922 ],\n",
       "         ...,\n",
       "         [-1.6081161 , -0.32639447,  0.04741105],\n",
       "         [-1.1544769 ,  1.1759338 , -0.0994335 ],\n",
       "         [-0.9456738 , -0.61019504,  0.21835032]],\n",
       "\n",
       "        [[-1.2332631 ,  0.04229557, -0.01040097],\n",
       "         [-0.1729883 ,  1.261198  , -0.5768167 ],\n",
       "         [-0.8761514 ,  1.4456713 ,  1.010124  ],\n",
       "         ...,\n",
       "         [ 0.37871286,  1.3236547 ,  2.0703628 ],\n",
       "         [-1.3714577 ,  0.37935296, -0.49204952],\n",
       "         [-0.69932413, -1.1115206 ,  0.7220743 ]],\n",
       "\n",
       "        [[ 0.35281965, -0.7270342 , -1.8135774 ],\n",
       "         [ 0.2016058 ,  0.46136948,  0.39102268],\n",
       "         [ 1.9704645 , -1.4470246 , -0.1612656 ],\n",
       "         ...,\n",
       "         [ 0.5666618 , -0.22855341, -0.8491719 ],\n",
       "         [-2.116388  , -0.44444978, -1.1786937 ],\n",
       "         [ 0.5822642 ,  0.9540981 , -0.39033303]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.4019528 ,  1.1341777 , -0.6776014 ],\n",
       "         [ 0.13331714,  1.401918  , -0.7809523 ],\n",
       "         [ 0.14826053, -0.5082358 ,  0.45821202],\n",
       "         ...,\n",
       "         [-0.33710626, -0.77570724,  0.52981   ],\n",
       "         [ 0.2593577 , -0.35205707,  1.3483618 ],\n",
       "         [ 0.5852536 , -0.22009704,  1.0258974 ]],\n",
       "\n",
       "        [[-0.28386134, -0.75880855,  0.72584283],\n",
       "         [-1.1145384 ,  1.4384156 ,  0.41125724],\n",
       "         [-0.5791751 , -0.55190694,  1.0898347 ],\n",
       "         ...,\n",
       "         [-0.2268023 , -1.4128348 , -1.0096537 ],\n",
       "         [-1.1942952 ,  0.18609719,  0.05208822],\n",
       "         [ 0.97929275,  1.5727268 ,  0.06807159]],\n",
       "\n",
       "        [[-1.7757784 ,  0.39900306,  0.05831234],\n",
       "         [-1.1008818 ,  2.1861746 , -0.02210025],\n",
       "         [ 0.650286  , -1.4315585 ,  1.1198479 ],\n",
       "         ...,\n",
       "         [-2.0565376 ,  2.1521122 , -0.464342  ],\n",
       "         [-0.03429282, -0.2474434 , -0.7390908 ],\n",
       "         [ 1.1307839 ,  0.979326  ,  0.20334361]]],\n",
       "\n",
       "\n",
       "       [[[-0.42116284, -1.2348437 ,  1.3276658 ],\n",
       "         [ 1.6795839 ,  1.5969809 , -0.43829536],\n",
       "         [-0.15179697, -0.17531405,  1.6200796 ],\n",
       "         ...,\n",
       "         [ 1.0367701 , -0.44446617, -1.5160245 ],\n",
       "         [-1.2833748 ,  2.2805116 ,  1.0169384 ],\n",
       "         [-0.02968351, -0.83948463,  0.91479963]],\n",
       "\n",
       "        [[ 0.915777  , -0.1763143 , -1.9035958 ],\n",
       "         [ 0.5787966 , -0.7798234 ,  0.16309717],\n",
       "         [-0.27179778, -1.832727  ,  1.5273812 ],\n",
       "         ...,\n",
       "         [ 0.73520136,  0.11790864,  0.5627834 ],\n",
       "         [-0.288655  , -0.49997422,  1.4144139 ],\n",
       "         [-0.45210707,  0.77639925,  1.7305467 ]],\n",
       "\n",
       "        [[-1.7390394 , -1.2936013 ,  0.0663847 ],\n",
       "         [-0.8462659 ,  0.14499503,  1.5340972 ],\n",
       "         [ 0.3888978 , -0.24659175,  0.49918595],\n",
       "         ...,\n",
       "         [ 0.5638036 ,  0.19210152,  0.9233307 ],\n",
       "         [ 1.7911956 ,  1.5328017 , -0.09511712],\n",
       "         [ 2.6465385 , -0.76002425,  0.18915282]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.7823817 , -0.7998029 , -1.2075379 ],\n",
       "         [-0.28648093, -0.8171874 ,  1.3421313 ],\n",
       "         [ 1.3981982 , -0.72333026, -0.45305407],\n",
       "         ...,\n",
       "         [-0.09762272,  0.2268418 , -1.47997   ],\n",
       "         [ 0.44433072, -0.19667405, -1.0166553 ],\n",
       "         [-0.6748465 ,  0.11135926,  1.3739436 ]],\n",
       "\n",
       "        [[-0.25020692, -1.1496447 , -2.4499934 ],\n",
       "         [ 0.20567456,  0.15952383,  0.48747343],\n",
       "         [ 1.5518395 , -0.2506782 ,  0.14129493],\n",
       "         ...,\n",
       "         [-0.26196626,  0.37355408,  0.90561855],\n",
       "         [-0.7662242 ,  2.235749  , -1.3935505 ],\n",
       "         [ 1.1914988 , -1.4314258 , -0.7280169 ]],\n",
       "\n",
       "        [[-2.1360145 ,  0.29978323,  0.52516365],\n",
       "         [-0.15668148, -2.6373081 ,  0.50257236],\n",
       "         [-0.41128877, -0.5989711 , -1.1876925 ],\n",
       "         ...,\n",
       "         [ 1.5332217 ,  0.68650335,  0.28639972],\n",
       "         [ 1.1058137 ,  1.7168708 , -0.2965972 ],\n",
       "         [ 1.6319546 ,  1.1752248 , -0.17931518]]]], dtype=float32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Buat tensor 4 dimensi. Tensor berisi empat gambar. Ukuran setiap gambar adalah \n",
    "# 100 x 100 x 3.\n",
    "tensor_h = tf.random.normal([4,100,100,3])\n",
    "tensor_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b0abdae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(100, 100, 3), dtype=float32, numpy=\n",
       "array([[[ 1.4562087 , -1.4419875 , -0.0783527 ],\n",
       "        [ 0.27075505, -2.3132937 , -1.4670018 ],\n",
       "        [-0.25047097, -1.0218505 ,  0.9714081 ],\n",
       "        ...,\n",
       "        [ 1.0086595 , -0.52435637,  1.3170794 ],\n",
       "        [ 0.957892  ,  0.9369246 ,  0.5940449 ],\n",
       "        [-0.98134524,  0.5684921 , -1.4435033 ]],\n",
       "\n",
       "       [[-0.54834515,  0.57787573, -0.69312245],\n",
       "        [-0.04144788, -0.01168209, -0.33810532],\n",
       "        [-0.85379535, -0.49939635,  1.2713962 ],\n",
       "        ...,\n",
       "        [-0.4496524 ,  1.6964539 ,  0.5302422 ],\n",
       "        [-0.32005426, -0.64427924, -2.070247  ],\n",
       "        [-1.6325626 ,  2.5323832 ,  2.351591  ]],\n",
       "\n",
       "       [[ 1.4742026 , -0.4427584 ,  1.3805368 ],\n",
       "        [-0.8890921 , -0.35605747, -1.2094271 ],\n",
       "        [-0.4607863 ,  0.42250872,  1.340159  ],\n",
       "        ...,\n",
       "        [-0.60539794, -0.9810849 , -0.7736408 ],\n",
       "        [-1.5524977 ,  0.4837724 , -1.6826777 ],\n",
       "        [-0.9810144 ,  0.07747748,  0.96968454]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-2.4536188 , -0.7396818 ,  1.2800527 ],\n",
       "        [-1.5141575 , -1.2606256 , -1.1759346 ],\n",
       "        [ 0.04149139,  0.32904503,  0.3360036 ],\n",
       "        ...,\n",
       "        [-0.5229448 ,  0.9758602 ,  1.2034825 ],\n",
       "        [ 0.73482186,  0.88683814, -0.26354563],\n",
       "        [ 0.9032049 ,  2.7317035 , -0.49074164]],\n",
       "\n",
       "       [[-0.09721033, -0.02016292, -1.4593234 ],\n",
       "        [ 0.4018314 , -0.5323158 ,  0.13737352],\n",
       "        [-0.43385702,  0.07326435,  0.37679964],\n",
       "        ...,\n",
       "        [-0.6510627 , -0.2100805 ,  1.2958064 ],\n",
       "        [ 0.52936983, -0.06314103, -1.5466092 ],\n",
       "        [ 1.4888753 ,  0.884846  ,  0.09351158]],\n",
       "\n",
       "       [[-1.2838606 , -0.44548783, -1.6666826 ],\n",
       "        [-0.28075293,  0.0091745 , -1.584549  ],\n",
       "        [-1.9191386 , -0.7787316 ,  0.82842547],\n",
       "        ...,\n",
       "        [-2.3215394 ,  1.4999858 ,  0.42965567],\n",
       "        [ 0.6500103 ,  0.11333774, -1.2496572 ],\n",
       "        [-1.3060138 ,  0.4483606 , -0.16933577]]], dtype=float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extract gambar pertama.\n",
    "tensor_h[0,:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c0706d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 100, 100, 3), dtype=float32, numpy=\n",
       "array([[[[ 1.4562087 , -1.4419875 , -0.0783527 ],\n",
       "         [ 0.27075505, -2.3132937 , -1.4670018 ],\n",
       "         [-0.25047097, -1.0218505 ,  0.9714081 ],\n",
       "         ...,\n",
       "         [ 1.0086595 , -0.52435637,  1.3170794 ],\n",
       "         [ 0.957892  ,  0.9369246 ,  0.5940449 ],\n",
       "         [-0.98134524,  0.5684921 , -1.4435033 ]],\n",
       "\n",
       "        [[-0.54834515,  0.57787573, -0.69312245],\n",
       "         [-0.04144788, -0.01168209, -0.33810532],\n",
       "         [-0.85379535, -0.49939635,  1.2713962 ],\n",
       "         ...,\n",
       "         [-0.4496524 ,  1.6964539 ,  0.5302422 ],\n",
       "         [-0.32005426, -0.64427924, -2.070247  ],\n",
       "         [-1.6325626 ,  2.5323832 ,  2.351591  ]],\n",
       "\n",
       "        [[ 1.4742026 , -0.4427584 ,  1.3805368 ],\n",
       "         [-0.8890921 , -0.35605747, -1.2094271 ],\n",
       "         [-0.4607863 ,  0.42250872,  1.340159  ],\n",
       "         ...,\n",
       "         [-0.60539794, -0.9810849 , -0.7736408 ],\n",
       "         [-1.5524977 ,  0.4837724 , -1.6826777 ],\n",
       "         [-0.9810144 ,  0.07747748,  0.96968454]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-2.4536188 , -0.7396818 ,  1.2800527 ],\n",
       "         [-1.5141575 , -1.2606256 , -1.1759346 ],\n",
       "         [ 0.04149139,  0.32904503,  0.3360036 ],\n",
       "         ...,\n",
       "         [-0.5229448 ,  0.9758602 ,  1.2034825 ],\n",
       "         [ 0.73482186,  0.88683814, -0.26354563],\n",
       "         [ 0.9032049 ,  2.7317035 , -0.49074164]],\n",
       "\n",
       "        [[-0.09721033, -0.02016292, -1.4593234 ],\n",
       "         [ 0.4018314 , -0.5323158 ,  0.13737352],\n",
       "         [-0.43385702,  0.07326435,  0.37679964],\n",
       "         ...,\n",
       "         [-0.6510627 , -0.2100805 ,  1.2958064 ],\n",
       "         [ 0.52936983, -0.06314103, -1.5466092 ],\n",
       "         [ 1.4888753 ,  0.884846  ,  0.09351158]],\n",
       "\n",
       "        [[-1.2838606 , -0.44548783, -1.6666826 ],\n",
       "         [-0.28075293,  0.0091745 , -1.584549  ],\n",
       "         [-1.9191386 , -0.7787316 ,  0.82842547],\n",
       "         ...,\n",
       "         [-2.3215394 ,  1.4999858 ,  0.42965567],\n",
       "         [ 0.6500103 ,  0.11333774, -1.2496572 ],\n",
       "         [-1.3060138 ,  0.4483606 , -0.16933577]]],\n",
       "\n",
       "\n",
       "       [[[ 0.58937025, -0.2530481 , -1.179859  ],\n",
       "         [ 0.20970912, -0.43773502,  0.54661274],\n",
       "         [-0.4556593 , -1.0287808 , -1.1576922 ],\n",
       "         ...,\n",
       "         [-1.6081161 , -0.32639447,  0.04741105],\n",
       "         [-1.1544769 ,  1.1759338 , -0.0994335 ],\n",
       "         [-0.9456738 , -0.61019504,  0.21835032]],\n",
       "\n",
       "        [[-1.2332631 ,  0.04229557, -0.01040097],\n",
       "         [-0.1729883 ,  1.261198  , -0.5768167 ],\n",
       "         [-0.8761514 ,  1.4456713 ,  1.010124  ],\n",
       "         ...,\n",
       "         [ 0.37871286,  1.3236547 ,  2.0703628 ],\n",
       "         [-1.3714577 ,  0.37935296, -0.49204952],\n",
       "         [-0.69932413, -1.1115206 ,  0.7220743 ]],\n",
       "\n",
       "        [[ 0.35281965, -0.7270342 , -1.8135774 ],\n",
       "         [ 0.2016058 ,  0.46136948,  0.39102268],\n",
       "         [ 1.9704645 , -1.4470246 , -0.1612656 ],\n",
       "         ...,\n",
       "         [ 0.5666618 , -0.22855341, -0.8491719 ],\n",
       "         [-2.116388  , -0.44444978, -1.1786937 ],\n",
       "         [ 0.5822642 ,  0.9540981 , -0.39033303]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.4019528 ,  1.1341777 , -0.6776014 ],\n",
       "         [ 0.13331714,  1.401918  , -0.7809523 ],\n",
       "         [ 0.14826053, -0.5082358 ,  0.45821202],\n",
       "         ...,\n",
       "         [-0.33710626, -0.77570724,  0.52981   ],\n",
       "         [ 0.2593577 , -0.35205707,  1.3483618 ],\n",
       "         [ 0.5852536 , -0.22009704,  1.0258974 ]],\n",
       "\n",
       "        [[-0.28386134, -0.75880855,  0.72584283],\n",
       "         [-1.1145384 ,  1.4384156 ,  0.41125724],\n",
       "         [-0.5791751 , -0.55190694,  1.0898347 ],\n",
       "         ...,\n",
       "         [-0.2268023 , -1.4128348 , -1.0096537 ],\n",
       "         [-1.1942952 ,  0.18609719,  0.05208822],\n",
       "         [ 0.97929275,  1.5727268 ,  0.06807159]],\n",
       "\n",
       "        [[-1.7757784 ,  0.39900306,  0.05831234],\n",
       "         [-1.1008818 ,  2.1861746 , -0.02210025],\n",
       "         [ 0.650286  , -1.4315585 ,  1.1198479 ],\n",
       "         ...,\n",
       "         [-2.0565376 ,  2.1521122 , -0.464342  ],\n",
       "         [-0.03429282, -0.2474434 , -0.7390908 ],\n",
       "         [ 1.1307839 ,  0.979326  ,  0.20334361]]]], dtype=float32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ekstrak satu irisan dengan interval dua gambar.\n",
    "tensor_h[::2,...]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b49d617a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 100, 100, 3), dtype=float32, numpy=\n",
       "array([[[[-0.42116284, -1.2348437 ,  1.3276658 ],\n",
       "         [ 1.6795839 ,  1.5969809 , -0.43829536],\n",
       "         [-0.15179697, -0.17531405,  1.6200796 ],\n",
       "         ...,\n",
       "         [ 1.0367701 , -0.44446617, -1.5160245 ],\n",
       "         [-1.2833748 ,  2.2805116 ,  1.0169384 ],\n",
       "         [-0.02968351, -0.83948463,  0.91479963]],\n",
       "\n",
       "        [[ 0.915777  , -0.1763143 , -1.9035958 ],\n",
       "         [ 0.5787966 , -0.7798234 ,  0.16309717],\n",
       "         [-0.27179778, -1.832727  ,  1.5273812 ],\n",
       "         ...,\n",
       "         [ 0.73520136,  0.11790864,  0.5627834 ],\n",
       "         [-0.288655  , -0.49997422,  1.4144139 ],\n",
       "         [-0.45210707,  0.77639925,  1.7305467 ]],\n",
       "\n",
       "        [[-1.7390394 , -1.2936013 ,  0.0663847 ],\n",
       "         [-0.8462659 ,  0.14499503,  1.5340972 ],\n",
       "         [ 0.3888978 , -0.24659175,  0.49918595],\n",
       "         ...,\n",
       "         [ 0.5638036 ,  0.19210152,  0.9233307 ],\n",
       "         [ 1.7911956 ,  1.5328017 , -0.09511712],\n",
       "         [ 2.6465385 , -0.76002425,  0.18915282]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.7823817 , -0.7998029 , -1.2075379 ],\n",
       "         [-0.28648093, -0.8171874 ,  1.3421313 ],\n",
       "         [ 1.3981982 , -0.72333026, -0.45305407],\n",
       "         ...,\n",
       "         [-0.09762272,  0.2268418 , -1.47997   ],\n",
       "         [ 0.44433072, -0.19667405, -1.0166553 ],\n",
       "         [-0.6748465 ,  0.11135926,  1.3739436 ]],\n",
       "\n",
       "        [[-0.25020692, -1.1496447 , -2.4499934 ],\n",
       "         [ 0.20567456,  0.15952383,  0.48747343],\n",
       "         [ 1.5518395 , -0.2506782 ,  0.14129493],\n",
       "         ...,\n",
       "         [-0.26196626,  0.37355408,  0.90561855],\n",
       "         [-0.7662242 ,  2.235749  , -1.3935505 ],\n",
       "         [ 1.1914988 , -1.4314258 , -0.7280169 ]],\n",
       "\n",
       "        [[-2.1360145 ,  0.29978323,  0.52516365],\n",
       "         [-0.15668148, -2.6373081 ,  0.50257236],\n",
       "         [-0.41128877, -0.5989711 , -1.1876925 ],\n",
       "         ...,\n",
       "         [ 1.5332217 ,  0.68650335,  0.28639972],\n",
       "         [ 1.1058137 ,  1.7168708 , -0.2965972 ],\n",
       "         [ 1.6319546 ,  1.1752248 , -0.17931518]]],\n",
       "\n",
       "\n",
       "       [[[ 0.58937025, -0.2530481 , -1.179859  ],\n",
       "         [ 0.20970912, -0.43773502,  0.54661274],\n",
       "         [-0.4556593 , -1.0287808 , -1.1576922 ],\n",
       "         ...,\n",
       "         [-1.6081161 , -0.32639447,  0.04741105],\n",
       "         [-1.1544769 ,  1.1759338 , -0.0994335 ],\n",
       "         [-0.9456738 , -0.61019504,  0.21835032]],\n",
       "\n",
       "        [[-1.2332631 ,  0.04229557, -0.01040097],\n",
       "         [-0.1729883 ,  1.261198  , -0.5768167 ],\n",
       "         [-0.8761514 ,  1.4456713 ,  1.010124  ],\n",
       "         ...,\n",
       "         [ 0.37871286,  1.3236547 ,  2.0703628 ],\n",
       "         [-1.3714577 ,  0.37935296, -0.49204952],\n",
       "         [-0.69932413, -1.1115206 ,  0.7220743 ]],\n",
       "\n",
       "        [[ 0.35281965, -0.7270342 , -1.8135774 ],\n",
       "         [ 0.2016058 ,  0.46136948,  0.39102268],\n",
       "         [ 1.9704645 , -1.4470246 , -0.1612656 ],\n",
       "         ...,\n",
       "         [ 0.5666618 , -0.22855341, -0.8491719 ],\n",
       "         [-2.116388  , -0.44444978, -1.1786937 ],\n",
       "         [ 0.5822642 ,  0.9540981 , -0.39033303]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.4019528 ,  1.1341777 , -0.6776014 ],\n",
       "         [ 0.13331714,  1.401918  , -0.7809523 ],\n",
       "         [ 0.14826053, -0.5082358 ,  0.45821202],\n",
       "         ...,\n",
       "         [-0.33710626, -0.77570724,  0.52981   ],\n",
       "         [ 0.2593577 , -0.35205707,  1.3483618 ],\n",
       "         [ 0.5852536 , -0.22009704,  1.0258974 ]],\n",
       "\n",
       "        [[-0.28386134, -0.75880855,  0.72584283],\n",
       "         [-1.1145384 ,  1.4384156 ,  0.41125724],\n",
       "         [-0.5791751 , -0.55190694,  1.0898347 ],\n",
       "         ...,\n",
       "         [-0.2268023 , -1.4128348 , -1.0096537 ],\n",
       "         [-1.1942952 ,  0.18609719,  0.05208822],\n",
       "         [ 0.97929275,  1.5727268 ,  0.06807159]],\n",
       "\n",
       "        [[-1.7757784 ,  0.39900306,  0.05831234],\n",
       "         [-1.1008818 ,  2.1861746 , -0.02210025],\n",
       "         [ 0.650286  , -1.4315585 ,  1.1198479 ],\n",
       "         ...,\n",
       "         [-2.0565376 ,  2.1521122 , -0.464342  ],\n",
       "         [-0.03429282, -0.2474434 , -0.7390908 ],\n",
       "         [ 1.1307839 ,  0.979326  ,  0.20334361]]],\n",
       "\n",
       "\n",
       "       [[[-1.7066896 ,  1.4898326 ,  1.078528  ],\n",
       "         [-1.0937972 , -1.4391749 , -0.05441549],\n",
       "         [-0.03208932, -1.2319435 ,  0.11344619],\n",
       "         ...,\n",
       "         [ 0.77300835,  0.0755583 , -0.39939067],\n",
       "         [ 0.9936557 ,  1.4485638 ,  0.667712  ],\n",
       "         [-2.3010478 ,  0.23390372,  0.49109066]],\n",
       "\n",
       "        [[ 0.8656338 ,  0.88571155, -1.7513474 ],\n",
       "         [-0.51496935, -0.16807957,  1.5247873 ],\n",
       "         [-0.98722047, -0.82758063, -0.4402495 ],\n",
       "         ...,\n",
       "         [ 0.54505396, -0.04586942,  1.9019759 ],\n",
       "         [ 0.5951845 , -0.6126047 ,  0.07897622],\n",
       "         [-0.77430934, -2.1448634 ,  1.2670382 ]],\n",
       "\n",
       "        [[ 1.9834658 ,  0.8584483 , -0.16268064],\n",
       "         [ 1.1441928 ,  0.11874662, -0.31415635],\n",
       "         [ 0.7854686 , -1.2267128 ,  1.7966653 ],\n",
       "         ...,\n",
       "         [-0.03814313, -0.73275435,  0.46984968],\n",
       "         [ 2.1732945 , -1.2719408 , -1.6309074 ],\n",
       "         [-1.0988913 ,  1.2687498 , -0.6717013 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.3851376 , -0.841486  , -1.6923465 ],\n",
       "         [-2.0379348 , -0.27640057, -0.65749156],\n",
       "         [-1.053849  ,  1.3897476 , -0.76481444],\n",
       "         ...,\n",
       "         [ 0.22525978,  0.736188  , -1.9164859 ],\n",
       "         [-0.6167677 , -1.2439477 , -0.05458681],\n",
       "         [ 0.3183658 ,  0.7209911 , -1.7651904 ]],\n",
       "\n",
       "        [[-0.33534473,  1.123207  , -0.4705633 ],\n",
       "         [ 1.9338088 , -1.4979734 , -1.0288324 ],\n",
       "         [-2.1232493 , -0.17211029,  0.5542008 ],\n",
       "         ...,\n",
       "         [-1.170167  , -1.2147437 ,  0.31513438],\n",
       "         [-0.58993065, -0.27416706,  1.4123936 ],\n",
       "         [-0.32437798, -0.15596837,  0.54083633]],\n",
       "\n",
       "        [[-1.3853852 ,  0.20503455,  0.04193249],\n",
       "         [-0.15172525,  0.40373498,  1.0168786 ],\n",
       "         [-0.14487897,  0.14349094, -2.2299035 ],\n",
       "         ...,\n",
       "         [ 0.5927507 ,  1.8509623 , -0.6380369 ],\n",
       "         [-1.2425569 , -1.3272448 ,  0.03280028],\n",
       "         [-1.0473673 , -0.6058104 ,  0.84692395]]],\n",
       "\n",
       "\n",
       "       [[[ 1.4562087 , -1.4419875 , -0.0783527 ],\n",
       "         [ 0.27075505, -2.3132937 , -1.4670018 ],\n",
       "         [-0.25047097, -1.0218505 ,  0.9714081 ],\n",
       "         ...,\n",
       "         [ 1.0086595 , -0.52435637,  1.3170794 ],\n",
       "         [ 0.957892  ,  0.9369246 ,  0.5940449 ],\n",
       "         [-0.98134524,  0.5684921 , -1.4435033 ]],\n",
       "\n",
       "        [[-0.54834515,  0.57787573, -0.69312245],\n",
       "         [-0.04144788, -0.01168209, -0.33810532],\n",
       "         [-0.85379535, -0.49939635,  1.2713962 ],\n",
       "         ...,\n",
       "         [-0.4496524 ,  1.6964539 ,  0.5302422 ],\n",
       "         [-0.32005426, -0.64427924, -2.070247  ],\n",
       "         [-1.6325626 ,  2.5323832 ,  2.351591  ]],\n",
       "\n",
       "        [[ 1.4742026 , -0.4427584 ,  1.3805368 ],\n",
       "         [-0.8890921 , -0.35605747, -1.2094271 ],\n",
       "         [-0.4607863 ,  0.42250872,  1.340159  ],\n",
       "         ...,\n",
       "         [-0.60539794, -0.9810849 , -0.7736408 ],\n",
       "         [-1.5524977 ,  0.4837724 , -1.6826777 ],\n",
       "         [-0.9810144 ,  0.07747748,  0.96968454]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-2.4536188 , -0.7396818 ,  1.2800527 ],\n",
       "         [-1.5141575 , -1.2606256 , -1.1759346 ],\n",
       "         [ 0.04149139,  0.32904503,  0.3360036 ],\n",
       "         ...,\n",
       "         [-0.5229448 ,  0.9758602 ,  1.2034825 ],\n",
       "         [ 0.73482186,  0.88683814, -0.26354563],\n",
       "         [ 0.9032049 ,  2.7317035 , -0.49074164]],\n",
       "\n",
       "        [[-0.09721033, -0.02016292, -1.4593234 ],\n",
       "         [ 0.4018314 , -0.5323158 ,  0.13737352],\n",
       "         [-0.43385702,  0.07326435,  0.37679964],\n",
       "         ...,\n",
       "         [-0.6510627 , -0.2100805 ,  1.2958064 ],\n",
       "         [ 0.52936983, -0.06314103, -1.5466092 ],\n",
       "         [ 1.4888753 ,  0.884846  ,  0.09351158]],\n",
       "\n",
       "        [[-1.2838606 , -0.44548783, -1.6666826 ],\n",
       "         [-0.28075293,  0.0091745 , -1.584549  ],\n",
       "         [-1.9191386 , -0.7787316 ,  0.82842547],\n",
       "         ...,\n",
       "         [-2.3215394 ,  1.4999858 ,  0.42965567],\n",
       "         [ 0.6500103 ,  0.11333774, -1.2496572 ],\n",
       "         [-1.3060138 ,  0.4483606 , -0.16933577]]]], dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Mengiris data dari elemen terakhir.\n",
    "tensor_h[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb21692",
   "metadata": {},
   "source": [
    "1.2.1.2.2 Indexing <br>\n",
    "The basic format of an index is <b>a[d1][d2][d3]</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c156bf06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=-1.3758565>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pilih piksel di posisi [20,40] di saluran kedua dari gambar pertama.\n",
    "tensor_h[0][19][39][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd83b84e",
   "metadata": {},
   "source": [
    "## 1.2.1.4 Tensor Dimension Modification\n",
    "## 1.2.1.4.1 Viewing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "08c9bb68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2)\n",
      "(2, 2)\n",
      "tf.Tensor([2 2], shape=(2,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "const_d_1 = tf.constant([[1, 2, 3, 4]],shape=[2,2], dtype=tf.float32)\n",
    "# Tiga metode umum untuk menampilkan dimensi:\n",
    "print(const_d_1.shape)\n",
    "print(const_d_1.get_shape())\n",
    "# Output adalah tensor. Nilai tensor menunjukkan ukuran dimensi tensor untuk ditampilkan.\n",
    "print(tf.shape(const_d_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06eb01d7",
   "metadata": {},
   "source": [
    "## 1.2.1.3.2 Dimension Reshaping <br>\n",
    "<b>tf.reshape(tensor,shape,name=None):</b><br>\n",
    "<ul>\n",
    "    <li><b>tensor:</b>input tensor.</li>\n",
    "    <li><b>shape:</b>dimension of the reshaped tensor.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ed5b008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1 2 3]\n",
      " [4 5 6]], shape=(2, 3), dtype=int32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       "array([[1, 2],\n",
       "       [3, 4],\n",
       "       [5, 6]])>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshape_1 = tf.constant([[1,2,3],[4,5,6]])\n",
    "print(reshape_1)\n",
    "tf.reshape(reshape_1, (3,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5da5af8",
   "metadata": {},
   "source": [
    "## 1.2.1.4.3 Expanding\n",
    "<b> tf.expand_dims(input,axis,name=None): </b> <br>\n",
    "<ul>\n",
    "    <li><b>input:</b>input tensor</li>\n",
    "    <li><b>axis:</b>adds a dimension after the <b>axis</b> dimension. When the number of dimensions of \n",
    "        the input data is D, the <b>axis</b> must fall in the range of [–(D + 1), D] (included). A \n",
    "negative value indicates adding a dimension in reverse order.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46af0625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of the original data: (100, 100, 3)\n",
      "add a dimension before the first dimension (axis = 0): (1, 100, 100, 3)\n",
      "add a dimension before the second dimension (axis = 1): (100, 1, 100, 3)\n",
      "add a dimension after the last dimension (axis = –1): (100, 100, 3, 1)\n"
     ]
    }
   ],
   "source": [
    "#Generate a 100 x 100 x 3 tensor to represent a 100 x 100 three-channel color image.\n",
    "expand_sample_1 = tf.random.normal([100,100,3], seed=1)\n",
    "print(\"size of the original data:\",expand_sample_1.shape)\n",
    "print(\"add a dimension before the first dimension (axis = 0):\", tf.expand_dims(expand_sample_1, axis=0).shape)\n",
    "\n",
    "print(\"add a dimension before the second dimension (axis = 1):\", tf.expand_dims(expand_sample_1, axis=1).shape)\n",
    "\n",
    "print(\"add a dimension after the last dimension (axis = –1):\", tf.expand_dims(expand_sample_1, axis=-1).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd49ff04",
   "metadata": {},
   "source": [
    "## 1.2.1.4.4 Squeezing <br>\n",
    "<b> tf.squeeze(input,axis=None,name=None): </b> <br>\n",
    "<ul>\n",
    "    <li><b>input:</b> input tensor</li>\n",
    "    <li><b>axis:</b>If axis is set to 1, dimension 1 needs to be deleted</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ced76aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of the original data: (1, 100, 100, 3)\n",
      "data size after dimension squeezing: (100, 100, 3)\n"
     ]
    }
   ],
   "source": [
    "#Generate a 100 x 100 x 3 tensor to represent a 100 x 100 three-channel color image.\n",
    "squeeze_sample_1 = tf.random.normal([1,100,100,3])\n",
    "print(\"size of the original data:\",squeeze_sample_1.shape)\n",
    "squeezed_sample_1 = tf.squeeze(expand_sample_1)\n",
    "print(\"data size after dimension squeezing:\",squeezed_sample_1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e5c7cb",
   "metadata": {},
   "source": [
    "## 1.2.1.4.5 Transposing <br>\n",
    "<b> tf.transpose(a,perm=None,conjugate=False,name='transpose'): </b> <br>\n",
    "<ul>\n",
    "    <li><b>a:</b> input tensor</li>\n",
    "    <li><b>perm:</b>tensor size sequence, generally used to transpose high-dimensional arrays</li>\n",
    "    <li><b>conjugate:</b> indicates complex number transpose.</li>\n",
    "    <li><b>name:</b>tensor name</li>\n",
    "    \n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cb1c5f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of the original data: (2, 3)\n",
      "size of transposed data: (3, 2)\n"
     ]
    }
   ],
   "source": [
    "#Input the tensor to be transposed, and call tf.transpose.\n",
    "trans_sample_1 = tf.constant([1,2,3,4,5,6],shape=[2,3])\n",
    "print(\"size of the original data:\",trans_sample_1.shape)\n",
    "transposed_sample_1 = tf.transpose(trans_sample_1)\n",
    "print(\"size of transposed data:\",transposed_sample_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1fc43f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of the original data: (4, 100, 200, 3)\n",
      "size of transposed data: (4, 200, 100, 3)\n"
     ]
    }
   ],
   "source": [
    "trans_sample_2 = tf.random.normal([4,100,200,3])\n",
    "print(\"size of the original data:\",trans_sample_2.shape)\n",
    "\n",
    "\n",
    "transposed_sample_2 = tf.transpose(trans_sample_2,[0,2,1,3])\n",
    "print(\"size of transposed data:\",transposed_sample_2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea494ebf",
   "metadata": {},
   "source": [
    "## 1.2.1.4.6 Broadcasting <br>\n",
    "<b> broadcast_to </b> is used to broadcast data from a low dimension to a high dimension. \n",
    "<b> tf.broadcast_to(input,shape,name=None): </b><br>\n",
    "<ul>\n",
    "    <li><b>input:</b> input tensor</li>\n",
    "    <li><b>shape:</b>size of the output tensor</li>    \n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f8c8d5ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original data: [1 2 3 4 5 6]\n",
      "broadcasted data: [[1 2 3 4 5 6]\n",
      " [1 2 3 4 5 6]\n",
      " [1 2 3 4 5 6]\n",
      " [1 2 3 4 5 6]]\n"
     ]
    }
   ],
   "source": [
    "broadcast_sample_1 = tf.constant([1,2,3,4,5,6])\n",
    "print(\"original data:\",broadcast_sample_1.numpy())\n",
    "broadcasted_sample_1 = tf.broadcast_to(broadcast_sample_1,shape=[4,6])\n",
    "print(\"broadcasted data:\",broadcasted_sample_1.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "28d4df20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 1  2  3]\n",
      " [11 12 13]\n",
      " [21 22 23]\n",
      " [31 32 33]], shape=(4, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# selama operasi, jika dua array memiliki bentuk yang berbeda, tensorflow secara otomatis memicu\n",
    "a = tf.constant([[ 0, 0, 0],\n",
    " [10,10,10],\n",
    " [20,20,20],\n",
    " [30,30,30]])\n",
    "b = tf.constant([1,2,3])\n",
    "print(a + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3daa38",
   "metadata": {},
   "source": [
    "## 1.2.1.5 Arithmetic Operations on Tensors\n",
    "## 1.2.1.5.1 Arithmetic Operators\n",
    "Main arithmetic operations include addition <b>(tf.add)</b>, subtraction <b>(tf.subtract)</b>, \n",
    "multiplication <b>(tf.multiply)</b>, division <b>(tf.divide)</b>, logarithm <b>(tf.math.log)</b>, and powers \n",
    "<b>(tf.pow)</b>. The following describes only one addition example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d8b1fa7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 4 11]\n",
      " [ 6 17]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant([[3, 5], [4, 8]])\n",
    "b = tf.constant([[1, 6], [2, 9]])\n",
    "print(tf.add(a, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087d39ca",
   "metadata": {},
   "source": [
    "## 1.2.1.5.2 Matrix Multiplication\n",
    "Matrix multiplication is implemented by calling <b>tf.matmul</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "66d4f913",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[13, 63],\n",
       "       [20, 96]])>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.matmul(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778bb5c6",
   "metadata": {},
   "source": [
    "## 1.2.1.5.3 Tensor Statistics Collection\n",
    "Methods for collecting tensor statistics include: <br>\n",
    "\n",
    "<ul>\n",
    "    <li><b>tf.reduce_min/max/mean():</b> alculates the minimum, maximum, and average \n",
    "values.</li>\n",
    "    <li><b>tf.argmax()/tf.argmin():</b>calculates the positions of the maximum and minimum \n",
    "values.</li>    \n",
    "    <li><b>tf.equal():</b>checks whether two tensors are equal by element.</li> \n",
    "    <li><b>tf.unique():</b>removes duplicate elements from tensors.</li> \n",
    "    <li><b>tf.nn.in_top_k(prediction, target, K):</b>calculates whether the predicted value is \n",
    "equal to the actual value, and returns a Boolean tensor.\n",
    "The following describes how to use tf.argmax(): Return the position of the maximum value.</li> \n",
    "    <li><b>input:</b></li> \n",
    "    <li><b>tf.argmax(input,axis)</b> input tensor</li> \n",
    "    <li><b>axis:</b>maximum output value in the axis dimension</li> \n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a4679b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input tensor: [[1 3 2]\n",
      " [2 5 8]\n",
      " [7 5 9]]\n",
      "locate the maximum value by column: [2 1 2]\n",
      "locate the maximum value by row: [1 2 2]\n"
     ]
    }
   ],
   "source": [
    "argmax_sample_1 = tf.constant([[1,3,2],[2,5,8],[7,5,9]])\n",
    "print(\"input tensor:\",argmax_sample_1.numpy())\n",
    "max_sample_1 = tf.argmax(argmax_sample_1, axis=0)\n",
    "max_sample_2 = tf.argmax(argmax_sample_1, axis=1)\n",
    "print(\"locate the maximum value by column:\",max_sample_1.numpy())\n",
    "print(\"locate the maximum value by row:\",max_sample_2.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9b85a3",
   "metadata": {},
   "source": [
    "## 1.2.1.6 Dimension-based Arithmetic Operations\n",
    "In TensorFlow, a series of operations of <b>tf.reduce_*</b> reduce tensor dimensions. The series \n",
    "of operations can be performed on dimensional elements of a tensor, for example, \n",
    "calculating the mean value by row and calculating a product of all elements in the tensor. \n",
    "Common operations include <b>tf.reduce_sum</b> (addition), <b>tf.reduce_prod</b> (multiplication), \n",
    "<b>tf.reduce_min</b> (minimum), <b>tf.reduce_max</b> (maximum), <b>tf.reduce_mean</b> (mean value)., \n",
    "<b>tf.reduce_all</b> (logical AND), <b>tf.reduce_any</b> (logical OR), and <b>tf.reduce_logsumexp\n",
    "(log(sum(exp)))</b>. <br>\n",
    "The methods for using these operations are similar. The following describes how to use \n",
    "<b>tf.reduce_sum</b>. Calculate the sum of elements in each dimension of a tensor \n",
    "<b>(tf.reduce_sum(input_tensor, axis=None, keepdims=False,name=None)):</b><br>\n",
    "<ul>\n",
    "    <li><b>input_tensor:</b> input tensor</li>\n",
    "    <li><b>axis:</b>specifies axis to be calculated. If this parameter is not specified, the mean value \n",
    "of all elements is calculated.</li>  \n",
    "    <li><b>keepdims:</b>specifies whether to keep dimensions. If this parameter is set to True, the \n",
    "output result retains the shape of the input tensor. If this parameter is set to False, \n",
    "dimensions of the output result decrease.</li>\n",
    "    <li><b>name:</b>operation name.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2de1cb3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original data [[1 2 3]\n",
      " [4 5 6]]\n",
      "calculate the sum of all elements in the tensor (axis = None):  21\n",
      "calculate the sum of elements in each column by column (axis = 0):  [5 7 9]\n",
      "calculate the sum of elements in each column by row (axis = 1):  [ 6 15]\n"
     ]
    }
   ],
   "source": [
    "reduce_sample_1 = tf.constant([1,2,3,4,5,6],shape=[2,3])\n",
    "print(\"original data\",reduce_sample_1.numpy())\n",
    "print(\"calculate the sum of all elements in the tensor (axis = None): \", tf.reduce_sum(reduce_sample_1,axis=None).numpy())\n",
    "print(\"calculate the sum of elements in each column by column (axis = 0): \", tf.reduce_sum(reduce_sample_1,axis=0).numpy())\n",
    "print(\"calculate the sum of elements in each column by row (axis = 1): \",tf.reduce_sum(reduce_sample_1,axis=1).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6477c5d",
   "metadata": {},
   "source": [
    "## 1.2.1.7 Tensor Concatenation and Splitting\n",
    "### 1.2.1.7.1 Tensor Concatenation\n",
    "In TensorFlow, tensor concatenation operations include: <br>\n",
    "\n",
    "<ul>\n",
    "    <li><b> tf.contact():</b> concatenates vectors based on the specified dimension, while keeping \n",
    "other dimensions unchanged.</li>\n",
    "    <li><b>tf.stack():</b>changes a group of R dimensional tensors to R+1 dimensional tensors, \n",
    "with the dimensions changed after the concatenation.\n",
    "tf.concat(values, axis, name='concat'):</li>  \n",
    "    <li><b>tf.concat(values, axis, name='concat'):</b></li>\n",
    "    <li><b>axis:</b>dimension to concatenate</li>\n",
    "    <li><b>name:</b>operation name</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ded6b925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sizes of the original data: (4, 100, 100, 3) (40, 100, 100, 3)\n",
      "size of the concatenated data: (44, 100, 100, 3)\n"
     ]
    }
   ],
   "source": [
    "concat_sample_1 = tf.random.normal([4,100,100,3])\n",
    "concat_sample_2 = tf.random.normal([40,100,100,3])\n",
    "print(\"sizes of the original data:\",concat_sample_1.shape,concat_sample_2.shape)\n",
    "concated_sample_1 = tf.concat([concat_sample_1,concat_sample_2],axis=0)\n",
    "print(\"size of the concatenated data:\",concated_sample_1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd4cb95",
   "metadata": {},
   "source": [
    "A dimension is added to the original matrix. In the same way, the parameter <b>axis</b>\n",
    "determines the position of the dimension. <b>tf.stack(values, axis=0, name='stack'):</b><br>\n",
    "<ul>\n",
    "    <li><b>values:</b> input tensors, a group of tensors with the same shape and data type.</li>\n",
    "    <li><b>axis:</b>dimension to concatenate</li>\n",
    "    <li><b>name:</b>operation name</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cec06162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sizes of the original data:  (100, 100, 3) (100, 100, 3)\n",
      "size of the concatenated data: (2, 100, 100, 3)\n"
     ]
    }
   ],
   "source": [
    "stack_sample_1 = tf.random.normal([100,100,3])\n",
    "stack_sample_2 = tf.random.normal([100,100,3])\n",
    "print(\"sizes of the original data: \",stack_sample_1.shape, stack_sample_2.shape)\n",
    "# Meningkatkan dimensi setelah concatenation. Jika sumbu diatur ke 0, dimensi ditambahkan sebelum dimensi pertama.\n",
    "stacked_sample_1 = tf.stack([stack_sample_1, stack_sample_2],axis=0)\n",
    "print(\"size of the concatenated data:\",stacked_sample_1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c0b59e",
   "metadata": {},
   "source": [
    "## 1.2.1.6.2 Tensor Splitting\n",
    "In TensorFlow, tensor splitting operations include: <br>\n",
    "<ul>\n",
    "    <li><b>tf.unstack():</b>splits a tensor by a specific dimension</li>\n",
    "    <li><b>tf.split():</b>splits a tensor into a specified number of sub tensors based on a specific \n",
    "dimension.<b>tf.split():</b>is more flexible than tf.unstack(). <b>tf.unstack(value,num=None,axis=0,name='unstack'):</b>\n",
    "    </li>\n",
    "    <li><b>value:</b>input tensor</li>\n",
    "    <li><b>num:</b>indicates that a list containing num elements is output. The value of num must \n",
    "be the same as the number of elements in the specified dimension. This parameter \n",
    "can generally be ignored.</li>\n",
    "    <li><b>axis:</b>indicates the dimension based on which the tensor is split.</li>\n",
    "    <li><b>name:</b>operation name</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6295b3d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(100, 100, 3), dtype=float32, numpy=\n",
       " array([[[-1.7439578 , -0.452856  , -1.6086322 ],\n",
       "         [ 0.9696205 ,  0.46748772,  2.3195589 ],\n",
       "         [-0.9768348 , -0.25406528, -0.04795438],\n",
       "         ...,\n",
       "         [ 1.1056106 ,  2.2055285 ,  0.00971037],\n",
       "         [-1.7035984 ,  0.02742777, -0.54292166],\n",
       "         [ 0.6477728 , -0.49370366,  1.9048221 ]],\n",
       " \n",
       "        [[-0.27364364,  2.5910017 ,  0.06988569],\n",
       "         [-0.9455167 , -0.10321755,  0.14187914],\n",
       "         [-0.2083685 ,  1.9593005 , -1.7841333 ],\n",
       "         ...,\n",
       "         [-1.6030679 , -1.112292  , -0.4593459 ],\n",
       "         [-0.26206005, -1.1423336 ,  0.49279553],\n",
       "         [-1.2334851 ,  0.43123516,  0.6370423 ]],\n",
       " \n",
       "        [[-1.0200204 ,  0.46256232, -1.0307139 ],\n",
       "         [ 0.85883266,  0.21545476, -0.79268736],\n",
       "         [-1.2603455 ,  0.9707374 ,  0.9456866 ],\n",
       "         ...,\n",
       "         [-2.6497018 , -1.7303035 ,  1.732519  ],\n",
       "         [-0.02757833, -1.1948768 ,  0.7024675 ],\n",
       "         [ 0.9887858 ,  0.5512852 , -1.0851724 ]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[-0.03956707, -1.7171483 , -1.1455586 ],\n",
       "         [ 0.2034418 ,  0.14406952, -0.6672592 ],\n",
       "         [ 1.271055  ,  0.5408697 , -0.3303284 ],\n",
       "         ...,\n",
       "         [ 0.46371478, -0.6335778 ,  0.667687  ],\n",
       "         [ 0.6066725 , -1.0688444 , -0.6822312 ],\n",
       "         [ 1.6706824 , -1.4087268 , -0.49545702]],\n",
       " \n",
       "        [[ 1.4371387 , -0.8053349 , -1.5897498 ],\n",
       "         [ 1.5494598 , -0.39388797, -1.0407295 ],\n",
       "         [ 0.8310991 ,  1.262471  , -0.9645737 ],\n",
       "         ...,\n",
       "         [ 0.11889943,  1.9027238 ,  2.5550992 ],\n",
       "         [-1.3858681 ,  0.14141448,  1.524101  ],\n",
       "         [ 0.89780337,  0.09323975,  1.4527446 ]],\n",
       " \n",
       "        [[-1.6589972 ,  0.7490311 , -0.03520874],\n",
       "         [-0.4231634 ,  1.0659496 ,  0.7286822 ],\n",
       "         [ 0.48843628,  1.1047076 ,  0.9309587 ],\n",
       "         ...,\n",
       "         [-0.8477696 ,  0.82033855,  0.72508436],\n",
       "         [-0.38089982,  0.2286669 ,  1.4003167 ],\n",
       "         [ 0.6845364 ,  1.0971023 ,  1.1093736 ]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(100, 100, 3), dtype=float32, numpy=\n",
       " array([[[-1.0720795 , -0.59815544,  0.42646164],\n",
       "         [ 1.382472  , -0.9525801 , -0.27841386],\n",
       "         [ 0.08691432, -1.0973375 , -0.80637515],\n",
       "         ...,\n",
       "         [-1.3046645 ,  0.6306855 , -0.20146798],\n",
       "         [ 0.50246835, -0.50918365, -0.87621504],\n",
       "         [ 3.0369678 , -1.0686789 ,  0.05054729]],\n",
       " \n",
       "        [[ 0.04078642,  0.72410214,  1.6609532 ],\n",
       "         [-0.86663777, -0.1131838 , -0.07123381],\n",
       "         [ 1.9338653 , -0.20526224, -0.30548668],\n",
       "         ...,\n",
       "         [-0.8154131 ,  0.17207113, -1.0024409 ],\n",
       "         [-0.2832405 , -1.7553986 , -0.97480196],\n",
       "         [-0.4164037 ,  0.24896397, -2.212291  ]],\n",
       " \n",
       "        [[-0.91184604, -0.60638505,  1.1212474 ],\n",
       "         [ 0.7016858 ,  0.3866832 , -0.06649251],\n",
       "         [-0.00960018, -0.10735603, -1.9216025 ],\n",
       "         ...,\n",
       "         [-0.3314852 ,  2.4362483 ,  0.53436446],\n",
       "         [ 1.3639845 ,  0.26045522, -1.1633303 ],\n",
       "         [-0.35169497,  0.08728161,  0.71919066]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 0.34573874,  1.2128111 , -1.4955255 ],\n",
       "         [ 0.18075691, -0.9219283 , -1.4500211 ],\n",
       "         [-0.01785667,  0.80033857, -1.481932  ],\n",
       "         ...,\n",
       "         [-0.07314591,  0.9972638 ,  0.71650904],\n",
       "         [-1.5123551 ,  0.65403444, -1.6189753 ],\n",
       "         [-0.634797  ,  0.20155892, -0.35346758]],\n",
       " \n",
       "        [[-0.07037248,  0.26812825,  0.7430778 ],\n",
       "         [ 0.48896927,  0.41524407,  0.1181886 ],\n",
       "         [-0.11814483, -0.42859626, -0.76048785],\n",
       "         ...,\n",
       "         [ 0.36194924,  1.6433139 , -1.0153947 ],\n",
       "         [ 2.0040944 ,  1.2630155 , -0.948919  ],\n",
       "         [ 0.1641968 ,  0.89262813,  0.90263   ]],\n",
       " \n",
       "        [[-1.360869  ,  1.3998649 , -1.3618196 ],\n",
       "         [ 0.6449882 ,  0.6733519 , -1.6640992 ],\n",
       "         [-0.6284999 ,  0.10174271,  1.472109  ],\n",
       "         ...,\n",
       "         [ 0.43488178,  0.8075234 ,  0.49778828],\n",
       "         [-0.9001793 ,  1.5160074 ,  2.3539934 ],\n",
       "         [ 0.7993079 ,  0.09462629,  0.178775  ]]], dtype=float32)>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Split data berdasarkan dimensi pertama dan output data perpecahan.\n",
    "tf.unstack(stacked_sample_1,axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6093c8ea",
   "metadata": {},
   "source": [
    "<b>tf.split(value, num_or_size_splits, axis=0):</b><br>\n",
    "<ul>\n",
    "    <li><b>tf.unstack():</b>splits a tensor by a specific dimension</li>\n",
    "    <li><b>tf.split():</b>splits a tensor into a specified number of sub tensors based on a specific \n",
    "dimension.<b>tf.split():</b>is more flexible than tf.unstack(). <b>tf.unstack(value,num=None,axis=0,name='unstack'):</b>\n",
    "    </li>\n",
    "    <li><b>value:</b>input tensor</li>\n",
    "    <li><b>num_or_size_splits:</b>number of sub tensors</li>\n",
    "    <li><b>axis:</b>indicates the dimension based on which the tensor is split.</li>\n",
    "</ul>\n",
    "\n",
    "<b>tf.split()</b> splits a tensor in either of the following ways:\n",
    "<ul>\n",
    "    <li>If the value of num_or_size_splits is an integer, the tensor is evenly split into sub \n",
    "tensors in the specified dimension (axis = D). </li>\n",
    "    <li>If the value of num_or_size_splits is a vector, the tensor is split into sub tensors \n",
    "based on the element value of the vector in the specified dimension (axis = D).\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bcb93446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of the original data: (10, 100, 100, 3)\n",
      "size of the split data when m_or_size_splits is set to 10:  (5, 2, 100, 100, 3)\n",
      "sizes of the split data when num_or_size_splits is set to [3,5,2]: (3, 100, 100, 3) (5, 100, 100, 3) (2, 100, 100, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "split_sample_1 = tf.random.normal([10,100,100,3])\n",
    "print(\"size of the original data:\",split_sample_1.shape)\n",
    "splited_sample_1 = tf.split(split_sample_1, num_or_size_splits=5,axis=0)\n",
    "print(\"size of the split data when m_or_size_splits is set to 10: \",np.shape(splited_sample_1))\n",
    "splited_sample_2 = tf.split(split_sample_1, num_or_size_splits=[3,5,2],axis=0)\n",
    "print(\"sizes of the split data when num_or_size_splits is set to [3,5,2]:\",\n",
    " np.shape(splited_sample_2[0]),\n",
    " np.shape(splited_sample_2[1]),\n",
    " np.shape(splited_sample_2[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375067db",
   "metadata": {},
   "source": [
    "## 1.2.1.8 Tensor Sorting\n",
    "In TensorFlow, tensor sorting operations include: <br>\n",
    "\n",
    "<ul>\n",
    "    <li><b>tf.sort():</b>sorts tensors in ascending or descending order and returns the sorted \n",
    "tensors.</li>\n",
    "    <li><b>tf.argsort():</b>sorts tensors in ascending or descending order, and returns tensor \n",
    "indexes.\n",
    "    </li>\n",
    "    <li><b>tf.nn.top_k()</b>returns the first k maximum values. \n",
    "tf.sort/argsort(input, direction, axis):</li>\n",
    "    <li><b>direction:</b> sorting order, which can be set to DESCENDING (descending order) or \n",
    "ASCENDING (ascending order). The default value is ASCENDING.</li>\n",
    "    <li><b>axis:</b> sorting by the dimension specified by axis. The default value of axis is –1, \n",
    "indicating the last dimension.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4d83dc77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input tensor: [2 7 4 1 8 5 9 3 0 6]\n",
      "tensor sorted in ascending order: [0 1 2 3 4 5 6 7 8 9]\n",
      "indexes of elements in ascending order: [8 3 0 7 2 5 9 1 4 6]\n"
     ]
    }
   ],
   "source": [
    "sort_sample_1 = tf.random.shuffle(tf.range(10))\n",
    "print(\"input tensor:\",sort_sample_1.numpy())\n",
    "sorted_sample_1 = tf.sort(sort_sample_1, direction=\"ASCENDING\")\n",
    "print(\"tensor sorted in ascending order:\",sorted_sample_1.numpy())\n",
    "sorted_sample_2 = tf.argsort(sort_sample_1,direction=\"ASCENDING\")\n",
    "print(\"indexes of elements in ascending order:\",sorted_sample_2.numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6898d2",
   "metadata": {},
   "source": [
    "<b>tf.nn.top_k(input,K,sorted=TRUE):</b><br>\n",
    "<ul>\n",
    "    <li><b>input:</b>input tensor</li>\n",
    "    <li><b>K:</b>the first k values to be output and their indexes\n",
    "    </li>\n",
    "    <li><b>sorted:</b>When sorted is set to TRUE, the tensor is sorted in ascending order. When \n",
    "sorted is set to FALSE, the tensor is sorted in descending order.</li>\n",
    "    <li><b>values:</b> k maximum values in each row.</li>\n",
    "    <li><b>indices:</b> positions of elements in the last dimension of the input tensor.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6644b8b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input tensor: [2 7 4 1 8 5 9 3 0 6]\n",
      "first five values in ascending order: [9 8 7 6 5]\n",
      "indexes of the first five values in ascending order: [6 4 1 9 5]\n"
     ]
    }
   ],
   "source": [
    "values, index = tf.nn.top_k(sort_sample_1,5)\n",
    "print(\"input tensor:\",sort_sample_1.numpy())\n",
    "print(\"first five values in ascending order:\", values.numpy())\n",
    "print(\"indexes of the first five values in ascending order:\", index.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0392fa",
   "metadata": {},
   "source": [
    "## 1.2.2 Eager Execution Mode of TensorFlow 2\n",
    "Eager Execution mode: <br>\n",
    "The Eager Execution mode of TensorFlow is a type of imperative programming, which is \n",
    "the same as native Python. When you perform a particular operation, the system \n",
    "immediately returns a result. \n",
    "Graph mode: <br>\n",
    "TensorFlow 1.0 adopts the Graph mode to first build a computational graph, enable a \n",
    "Session, and then feed actual data to obtain a result. In Eager Execution mode, code \n",
    "debugging is easier, but the code execution efficiency is lower. The following implements \n",
    "simple multiplication by using TensorFlow to compare the differences between the Eager \n",
    "Execution mode and the Graph mode.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "267435b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[4. 6.]\n",
      " [4. 6.]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x = tf.ones((2, 2), dtype=tf.dtypes.float32)\n",
    "y = tf.constant([[1, 2],\n",
    " [3, 4]], dtype=tf.dtypes.float32)\n",
    "z = tf.matmul(x, y)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "22107724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4. 6.]\n",
      " [4. 6.]]\n"
     ]
    }
   ],
   "source": [
    "#Use the syntax of TensorFlow 1.x in TensorFlow 2.x. You can install the v1 compatibility \n",
    "# package in TensorFlow 2.0 to inherit the TensorFlow 1.x code and disable the eager execution \n",
    "# mode.\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_eager_execution()\n",
    "\n",
    "#Create a graph and define it as a computational graph.\n",
    "a = tf.ones((2, 2), dtype=tf.dtypes.float32)\n",
    "b = tf.constant([[1, 2],\n",
    " [3, 4]], dtype=tf.dtypes.float32)\n",
    "c = tf.matmul(a, b)\n",
    "\n",
    "#Enable the drawing function, and perform the multiplication operation to obtain data.\n",
    "with tf.Session() as sess:\n",
    " print(sess.run(c))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710558ac",
   "metadata": {},
   "source": [
    "Restart the kernel to restore TensorFlow 2.0 and enable the eager execution mode. Another \n",
    "advantage of the eager execution mode lies in availability of native Python functions, for \n",
    "example, the following condition statement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1041921c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"random_uniform/RandomUniform:0\", shape=(), dtype=float32)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-6afc34221048>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthre_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mif\u001b[0m \u001b[0mthre_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    444\u001b[0m         \u001b[0mnp_config\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_numpy_behavior\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m       \"\"\")\n\u001b[1;32m--> 446\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    447\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'numpy'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "thre_1 = tf.random.uniform([], 0, 1)\n",
    "x = tf.reshape(tf.range(0, 4), [2, 2])\n",
    "print(thre_1)\n",
    "if thre_1.numpy() > 0.5:\n",
    "    y = tf.matmul(x, x)\n",
    "else:\n",
    "    y = tf.add(x, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d36134c",
   "metadata": {},
   "source": [
    "## 1.2.3 TensorFlow2 AutoGraph\n",
    "\n",
    "When being used to comment out a function, the decorator <b> tf.function </b> can be called like \n",
    "any other function. <b>tf.function</b> will be compiled into a graph, so that it can run more \n",
    "efficiently on a GPU or a TPU. In this case, the function becomes an operation in TensorFlow. \n",
    "The function can be directly called to output a return value. However, the function is \n",
    "executed in graph mode and intermediate variable values cannot be directly viewed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e2b1dd5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"b:0\", shape=(), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'PartitionedCall:0' shape=(3, 3) dtype=float32>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@tf.function\n",
    "def simple_nn_layer(w,x,b):\n",
    "     print(b)\n",
    "     return tf.nn.relu(tf.matmul(w, x)+b)\n",
    "\n",
    "w = tf.random.uniform((3, 3))\n",
    "x = tf.random.uniform((3, 3))\n",
    "b = tf.constant(0.5, dtype='float32')\n",
    "\n",
    "\n",
    "simple_nn_layer(w,x,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7d27956d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time required for performing the computation of one convolutional neural network (CNN) layer in eager execution mode: 0.02770089999999925\n",
      "time required for performing the computation of one CNN layer in graph mode: 0.014418800000001397\n"
     ]
    }
   ],
   "source": [
    "#Use the timeit module to measure the execution time of a small code segment.\n",
    "import timeit\n",
    "#Create a convolutional layer.\n",
    "CNN_cell = tf.keras.layers.Conv2D(filters=100,kernel_size=2,strides=(1,1))\n",
    "\n",
    "#Use @tf.function to convert the operation into a graph.\n",
    "@tf.function\n",
    "def CNN_fn(image):\n",
    "    return CNN_cell(image)\n",
    "\n",
    "\n",
    "image = tf.zeros([100, 200, 200, 3])\n",
    "#Compare the execution time of the two modes.\n",
    "CNN_cell(image)\n",
    "CNN_fn(image)\n",
    "#Call timeit.timeit to measure the time required for executing the code 10 times.\n",
    "print(\"time required for performing the computation of one convolutional neural network (CNN) layer in eager execution mode:\", timeit.timeit(lambda: CNN_cell(image), number=10))\n",
    "print(\"time required for performing the computation of one CNN layer in graph mode:\", timeit.timeit(lambda: CNN_fn(image), number=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32ba0e2",
   "metadata": {},
   "source": [
    "The comparison shows that the code execution efficiency in graph mode is much higher. \n",
    "Therefore, the <b>@tf.function</b> function can be used to improve the code execution efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8615d7a3",
   "metadata": {},
   "source": [
    "# 2 Common Modules of TensorFlow 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ec6278",
   "metadata": {},
   "source": [
    "## 2.2 Procedure\n",
    "## 2.2.1 Model Building\n",
    "## 2.2.1.1 Building a Model by Stacking (tf.keras.Sequential)\n",
    "The most common way to build a model is to stack layers by using <b>tf.keras.Sequential.</b>\n",
    "## 2.2.1.2 Building a Functional Model\n",
    "Functional models are built mainly by using <b>tf.keras.Input</b> and <b>tf.keras.Model</b>, which are \n",
    "more complex than <b>tf.keras.Sequential</b> but have a good effect. Variables can be input at \n",
    "the same time or in different phases, and data can be output in different phases. Functional \n",
    "models are preferred if more than one model output is needed.\n",
    "Model stacking (.Sequential) vs Functional model (Model):<br>\n",
    "The <b>tf.keras.Sequential</b> model is a simple stack of layers and cannot represent any model. \n",
    "You can use the Keras functional model to build complex model topologies such as:\n",
    "\n",
    "Multi-input models.\n",
    "<ul>\n",
    "    <li><b>Multi-output models.</b></li>\n",
    "    <li><b>Models with shared layers.</b></li>\n",
    "    <li><b>Models with non-sequential data flows (for example, residual connections).</b></li>\n",
    "</ul>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "45ddca30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 32)]              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 32)                1056      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,442\n",
      "Trainable params: 2,442\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras.layers as layers \n",
    "model = tf.keras.Sequential()\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "#Use the output of the previous layer as the input of the next layer.\n",
    "x = tf.keras.Input(shape=(32,))\n",
    "h1 = layers.Dense(32, activation='relu')(x)\n",
    "h2 = layers.Dense(32, activation='relu')(h1)\n",
    "y = layers.Dense(10, activation='softmax')(h2)\n",
    "model_sample_2 = tf.keras.models.Model(x, y)\n",
    "\n",
    "\n",
    "#Print model information.\n",
    "model_sample_2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4016b7a",
   "metadata": {},
   "source": [
    "### 2.2.1.3 Building a Network Layer (tf.keras.layers)\n",
    "The tf.keras.layers module is used to configure neural network layers. Common classes \n",
    "include: <br>\n",
    "\n",
    "<ul>\n",
    "    <li><b>tf.keras.layers.Dense: </b>builds a fully connected layer.</li>\n",
    "    <li><b>tf.keras.layers.Conv2D:</b> builds a two-dimensional convolutional layer.</li>\n",
    "    <li><b>tf.keras.layers.MaxPooling2D/AveragePooling2D: </b> builds a maximum/average \n",
    "pooling layer.</li>\n",
    "    <li><b>tf.keras.layers.RNN: </b> builds a recurrent neural network layer.</li>\n",
    "    <li><b>tf.keras.layers.LSTM/tf.keras.layers.LSTMCell: </b> builds an LSTM network layer/LSTM unit.</li>\n",
    "    <li><b>tf.keras.layers.GRU/tf.keras.layers.GRUCell: </b> builds a GRU unit/GRU network layer.</li>\n",
    "    <li><b>tf.keras.layers.Embedding: </b> converts a positive integer (subscript) into a vector of a \n",
    "fixed size, for example, [[4],[20]]->[[0.25,0.1],[0.6,-0.2]]. The embedding layer can \n",
    "only be used as the first model layer.</li>\n",
    "     <li><b>tf.keras.layers.Dropout: </b> builds the dropout layer.</li>\n",
    "     <li><b>tf.keras.layers.MaxPooling2D/AveragePooling2D.</b></li>   \n",
    "    <li><b>tf.keras.layers.LSTM/tf.keras.layers.LSTMCell.</b> Main network configuration parameters in tf.keras.layers include</li>\n",
    "    <li><b>activation:</b> sets the activation function for the layer. By default, the system applies \n",
    "no activation function.</li>\n",
    "    <li><b>kernel_initializer and bias_initializer:</b> initialization schemes that create the layer's \n",
    "weights (kernel and bias). The default initializer is Glorot_uniform.</li>\n",
    "    <li><b>kernel_regularizer and bias_regularizer:</b>  regularization schemes that apply to the \n",
    "layer's weights (kernel and bias), such as L1 or L2 regularization. By default, the \n",
    "system applies no regularization function.</li>\n",
    "</ul>\n",
    "\n",
    "## 2.2.1.3.1 tf.keras.layers.Dense\n",
    "Main configuration parameters in tf.keras.layers.Dense include:<br>\n",
    "<ul>\n",
    "    <li><b> units:</b> number of neurons.</li>\n",
    "    <li><b>activation:</b>  sets the activation function.</li>\n",
    "    <li><b>use_bias:</b> indicates whether to use bias terms. Bias terms are used by default.</li>  \n",
    "    <li><b>kernel_initializer:</b> initialization schemes that create the layer's weight (kernel).</li>\n",
    "    <li><b>bias_initializer:</b> initialization schemes that create the layer's weight (bias).</li>\n",
    "    <li><b>kernel_regularizer:</b> regularization schemes that apply to the layer's weight (kernel).</li>\n",
    "    <li><b>bias_regularizer:</b> regularization schemes that apply to the layer's weight (bias).</li>\n",
    "    <li><b>activity_regularizer:</b> regular item applied to the output, a Regularizer object.</li>\n",
    "    <li><b>kernel_constraint:</b> a constraint applied to a weight.</li>\n",
    "    <li><b>bias_constraint:</b> ia constraint applied to a weight</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b7f5d16d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.dense.Dense at 0x2447d069fd0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers.Dense(32, activation='sigmoid')\n",
    "layers.Dense(32, activation=tf.sigmoid)\n",
    "\n",
    "\n",
    "layers.Dense(32, kernel_initializer=tf.keras.initializers.he_normal)\n",
    "\n",
    "\n",
    "layers.Dense(32, kernel_regularizer=tf.keras.regularizers.l2(0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb1ae84",
   "metadata": {},
   "source": [
    "## 2.2.1.3.2 tf.keras.layers.Conv2D\n",
    "Main configurable parameters in tf.keras.layers.Conv2D include: <br>\n",
    "<ul>\n",
    "    <li><b>filters:</b> number of convolution kernels (output dimensions).</li>\n",
    "    <li><b>kernel_size:</b> width and length of a convolution kernel.</li>\n",
    "    <li><b>strides:</b> convolution step.</li>\n",
    "    <li><b>padding: </b>zero padding policy.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0131449c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.convolutional.conv2d.Conv2D at 0x2447b0ebbb0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers.Conv2D(64,[1,1],2,padding='same',activation=\"relu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd09091c",
   "metadata": {},
   "source": [
    "## 2.2.1.3.3 tf.keras.layers.MaxPooling2D/AveragePooling2D\n",
    "Main configurable parameters in <b>tf.keras.layers.MaxPooling2D/AveragePooling2D</b>\n",
    "include: <br>\n",
    "\n",
    "<ul>\n",
    "    <li><b>pool_size:</b> size of the pooled kernel. For example, if the matrix (2, 2) is used, the \n",
    "picture becomes half of the original length in both dimensions. If this parameter is \n",
    "set to an integer, the integer is the values of all dimensions.</li>\n",
    "    <li><b>strides:</b> step.</li>\n",
    "    <li><b>Other parameters include padding and data_format.</b></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6f0e57c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.pooling.max_pooling2d.MaxPooling2D at 0x2447baba7c0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers.MaxPooling2D(pool_size=(2,2),strides=(2,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b63ee1",
   "metadata": {},
   "source": [
    "## 2.2.1.3.4 tf.keras.layers.LSTM/tf.keras.layers.LSTMCell\n",
    "Main configuration parameters in tf.keras.layers.LSTM/tf.keras.layers.LSTMCell include: <br>\n",
    "\n",
    "<ul>\n",
    "    <li><b>units:</b> output dimension</li>\n",
    "    <li><b>input_shape (timestep and input_dim):</b> timestep can be set to None, and \n",
    "input_dim indicates the input data dimension.</li>\n",
    "    <li><b>activation:</b> sets the activation function.</li>\n",
    "    <li><b>recurrent_activation:</b> activation function to use for the recurrent step.</li>    \n",
    "    <li><b>return_sequences:</b> If the value is True, the system returns the full sequence. If the \n",
    "value is False, the system returns the output of the last cell in the output sequence.</li>\n",
    "    <li><b>return_state:</b> Boolean value, indicates whether to return the last state in addition to \n",
    "the output.</li>\n",
    "    <li><b>dropout:</b> float between 0 and 1, fraction of the neurons to drop for the linear \n",
    "transformation of the inputs.</li>\n",
    "    <li><b>ecurrent_dropout:</b> float between 0 and 1, fraction of the neurons to drop for the \n",
    "linear transformation of the recurrent state.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e059c98",
   "metadata": {},
   "source": [
    "LSTMcell is the implementation unit of the LSTM layer.\n",
    "<ul>\n",
    "    <li><b>LSTM is an LSTM network layer.</b> number of neurons.</li>\n",
    "    <li><b>LSTMcell is a single-step computing unit, that is, an LSTM UNIT.</b></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d46598ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LSTM\n",
    "tf.keras.layers.LSTM(16, return_sequences=True)\n",
    "#LSTMCell\n",
    "x = tf.keras.Input((None, 3))\n",
    "y = layers.RNN(layers.LSTMCell(16))(x)\n",
    "model_lstm_3= tf.keras.Model(x, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075eb618",
   "metadata": {},
   "source": [
    "## 2.2.2 Model Training and Evaluation\n",
    "### 2.2.2.1 Compiling\n",
    "After a model is built, you can call compile to configure the learning process of the model: <br>\n",
    "\n",
    "<ul>\n",
    "    <li><b>compile(optimizer='rmsprop', loss=None, metrics=None, loss_weights=None)</b></li>\n",
    "    <li><b>optimizer:</b>  optimizer</li>\n",
    "    <li><b>loss:</b> loss function, cross entropy for binary tasks and MSE for regression tasks</li>\n",
    "    <li><b>metrics:</b>  model evaluation criteria during training and testing For example, metrics\n",
    "        can be set to <b>['accuracy']</b>. To specify multiple evaluation criteria, set a dictionary, for \n",
    "        example, set <b>metrics</b> to <b>{'output_a':'accuracy'}</b>.</li>    \n",
    "    <li><b>loss_weights:</b> If the model has multiple task outputs, you need to specify a weight \n",
    "for each output when optimizing the global loss.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b2aee156",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "#Determine the optimizer (optimizer), loss function (loss), and model evaluation method (metrics).\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
    " loss=tf.keras.losses.categorical_crossentropy,\n",
    " metrics=[tf.keras.metrics.categorical_accuracy])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6b166b",
   "metadata": {},
   "source": [
    "## 2.2.2.2 Training\n",
    "fit(x=None, y=None, batch_size=None, epochs=1, verbose=1, callbacks=None,\n",
    "validation_split=0.0, validation_data=None, shuffle=True, class_weight=None,\n",
    "sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None): <br>\n",
    "\n",
    "<ul>\n",
    "    <li><b>x:</b>Input training data</li>\n",
    "    <li><b>y:</b> Target (labeled) data</li>\n",
    "    <li><b>batch_size:</b> Number of samples for each gradient update The default value is 32.</li>\n",
    "    <li><b>epochs:</b>  number of iteration rounds of the training model</li>    \n",
    "    <li><b>verbose:</b> log display mode, set to 0, 1, or 2. 0 = Not displayed, 1 = Progress bar, 2 = \n",
    "One line is displayed for each round.</li>\n",
    "        <li><b>callbacks:</b> callback function used during training</li>\n",
    "        <li><b>validation_split:</b> fraction of the training data to be used as validation data</li>\n",
    "        <li><b>validation_data:</b> validation set. This parameter will overwrite validation_split.</li>\n",
    "        <li><b>shuffle:</b> indicates whether to shuffle data before each round of iteration. This \n",
    "parameter is invalid when steps_per_epoch is not None.</li>\n",
    "        <li><b>initial_epoch:</b> epoch at which to start training (useful for resuming a previous \n",
    "training weight)</li>\n",
    "        <li><b>steps_per_epoch:</b> set to the dataset size or batch_size</li>\n",
    "    <li><b>validation_steps:</b> This parameter is valid only when steps_per_epoch is specified. \n",
    "Total number of steps (batches of samples) to validate before stopping.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5c6183e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 200 samples\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 0s 134us/sample - loss: 12.7560 - categorical_accuracy: 0.0980 - val_loss: 12.5915 - val_categorical_accuracy: 0.0800\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 16us/sample - loss: 12.7542 - categorical_accuracy: 0.0970 - val_loss: 12.5897 - val_categorical_accuracy: 0.0800\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 16us/sample - loss: 12.7525 - categorical_accuracy: 0.0970 - val_loss: 12.5885 - val_categorical_accuracy: 0.0800\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 15us/sample - loss: 12.7519 - categorical_accuracy: 0.0980 - val_loss: 12.5888 - val_categorical_accuracy: 0.0800\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 17us/sample - loss: 12.7525 - categorical_accuracy: 0.0980 - val_loss: 12.5886 - val_categorical_accuracy: 0.0800\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 16us/sample - loss: 12.7509 - categorical_accuracy: 0.0980 - val_loss: 12.5867 - val_categorical_accuracy: 0.0800\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 17us/sample - loss: 12.7500 - categorical_accuracy: 0.0980 - val_loss: 12.5867 - val_categorical_accuracy: 0.0800\n",
      "Epoch 8/10\n",
      " 100/1000 [==>...........................] - ETA: 0s - loss: 12.6043 - categorical_accuracy: 0.1100"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\keras\\engine\\training_v1.py:2045: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 16us/sample - loss: 12.7491 - categorical_accuracy: 0.0980 - val_loss: 12.5848 - val_categorical_accuracy: 0.0800\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 16us/sample - loss: 12.7479 - categorical_accuracy: 0.0980 - val_loss: 12.5843 - val_categorical_accuracy: 0.0800\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 15us/sample - loss: 12.7475 - categorical_accuracy: 0.0980 - val_loss: 12.5844 - val_categorical_accuracy: 0.0800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2447d093be0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "train_x = np.random.random((1000, 36))\n",
    "train_y = np.random.random((1000, 10))\n",
    "val_x = np.random.random((200, 36))\n",
    "val_y = np.random.random((200, 10))\n",
    "model.fit(train_x, train_y, epochs=10, batch_size=100,\n",
    " validation_data=(val_x, val_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1561be",
   "metadata": {},
   "source": [
    "You can use <b>tf.data</b> to build training input pipelines for large datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d79dfc43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Expected a shuffled dataset but input dataset `x` is not shuffled. Please invoke `shuffle()` on input dataset.\n",
      "Train on 30 steps, validate on 3 steps\n",
      "Epoch 1/10\n",
      "30/30 [==============================] - 0s 4ms/step - batch: 14.5000 - size: 1.0000 - loss: 12.7914 - categorical_accuracy: 0.1010 - val_loss: 12.2872 - val_categorical_accuracy: 0.0938\n",
      "Epoch 2/10\n",
      "30/30 [==============================] - 0s 1ms/step - batch: 14.5000 - size: 1.0000 - loss: 12.6228 - categorical_accuracy: 0.1026 - val_loss: 12.2892 - val_categorical_accuracy: 0.0938\n",
      "Epoch 3/10\n",
      "30/30 [==============================] - 0s 1ms/step - batch: 14.5000 - size: 1.0000 - loss: 12.6889 - categorical_accuracy: 0.1015 - val_loss: 12.2907 - val_categorical_accuracy: 0.0938\n",
      "Epoch 4/10\n",
      "30/30 [==============================] - 0s 1ms/step - batch: 14.5000 - size: 1.0000 - loss: 12.7069 - categorical_accuracy: 0.0962 - val_loss: 12.2917 - val_categorical_accuracy: 0.0938\n",
      "Epoch 5/10\n",
      "30/30 [==============================] - 0s 1ms/step - batch: 14.5000 - size: 1.0000 - loss: 12.6840 - categorical_accuracy: 0.0951 - val_loss: 12.2930 - val_categorical_accuracy: 0.0938\n",
      "Epoch 6/10\n",
      "30/30 [==============================] - 0s 1ms/step - batch: 14.5000 - size: 1.0000 - loss: 12.6924 - categorical_accuracy: 0.1004 - val_loss: 12.2935 - val_categorical_accuracy: 0.0938\n",
      "Epoch 7/10\n",
      "30/30 [==============================] - 0s 1ms/step - batch: 14.5000 - size: 1.0000 - loss: 12.7029 - categorical_accuracy: 0.0994 - val_loss: 12.2931 - val_categorical_accuracy: 0.0938\n",
      "Epoch 8/10\n",
      "30/30 [==============================] - 0s 1ms/step - batch: 14.5000 - size: 1.0000 - loss: 12.6736 - categorical_accuracy: 0.0962 - val_loss: 12.2922 - val_categorical_accuracy: 0.0938\n",
      "Epoch 9/10\n",
      "30/30 [==============================] - 0s 1ms/step - batch: 14.5000 - size: 1.0000 - loss: 12.7173 - categorical_accuracy: 0.0972 - val_loss: 12.2904 - val_categorical_accuracy: 0.0938\n",
      "Epoch 10/10\n",
      "30/30 [==============================] - 0s 947us/step - batch: 14.5000 - size: 1.0000 - loss: 12.6820 - categorical_accuracy: 0.0983 - val_loss: 12.2880 - val_categorical_accuracy: 0.0938\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2447e2aab20>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((train_x, train_y))\n",
    "dataset = dataset.batch(32)\n",
    "dataset = dataset.repeat()\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_x, val_y))\n",
    "val_dataset = val_dataset.batch(32)\n",
    "val_dataset = val_dataset.repeat()\n",
    "model.fit(dataset, epochs=10, steps_per_epoch=30,\n",
    " validation_data=val_dataset, validation_steps=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debe2695",
   "metadata": {},
   "source": [
    "A callback function is an object passed to the model to customize and extend the model's \n",
    "behavior during training. We can write our own custom callbacks, or use\n",
    "built-in functions in tf.keras.callbacks. Common built-in callback functions are as follows: <br>\n",
    "<b>tf.keras.callbacks.ModelCheckpoint:</b> periodically save models.<br>\n",
    "<b>tf.keras.callbacks.LearningRateScheduler:</b> dynamically changes the learning rate.<br>\n",
    "<b>tf.keras.callbacks.EarlyStopping:</b> stops the training in advance.<br>\n",
    "<b>tf.keras.callbacks.TensorBoard:</b> uses TensorBoard.<br>\n",
    "#Set hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5ac915b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12.73719155883789, 0.096]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model evaluation\n",
    "test_x = np.random.random((1000, 36))\n",
    "test_y = np.random.random((1000, 10))\n",
    "model.evaluate(test_x, test_y, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0712a594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.12751256 0.05451351 0.13644868 ... 0.03803577 0.06081123 0.1085853 ]\n",
      " [0.37500113 0.02198305 0.0853503  ... 0.01477594 0.05770722 0.08776228]\n",
      " [0.07239673 0.02479582 0.06127168 ... 0.01993617 0.07017969 0.21282196]\n",
      " ...\n",
      " [0.07110521 0.05527172 0.10162633 ... 0.0205876  0.05042131 0.15260065]\n",
      " [0.19533636 0.06972186 0.07898767 ... 0.01691402 0.04981728 0.03686618]\n",
      " [0.17358656 0.05449742 0.08605574 ... 0.04816081 0.05889261 0.09501849]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\keras\\engine\\training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    }
   ],
   "source": [
    "#Model prediction\n",
    "pre_x = np.random.random((10, 36))\n",
    "result = model.predict(test_x,)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7585f745",
   "metadata": {},
   "source": [
    "# 3. Image Recognition\n",
    "\n",
    "## 3.1 Introduction <br>\n",
    "This experiment classifies images based on the mnist_fashion dataset.\n",
    "## 3.2 Procedure\n",
    "### 3.2.1 Importing the Dataset\n",
    "Step 1 Place the downloaded dataset in a correct location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4a4419e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: X=(60000, 28, 28), Y=(60000,)\n",
      "Test: X=(10000, 28, 28), Y=(10000,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "from keras.datasets import fashion_mnist\n",
    "# load dataset\n",
    "(X_train, Y_train), (X_test, Y_test) = fashion_mnist.load_data()\n",
    "\n",
    "print('Train: X=%s, Y=%s' % (X_train.shape, Y_train.shape))\n",
    "print('Test: X=%s, Y=%s' % (X_test.shape, Y_test.shape))\n",
    "# plot beberapa gambar\n",
    "for i in range(9):\n",
    "\t\n",
    "\tpyplot.subplot(330 + 1 + i)\n",
    "\t\n",
    "\tpyplot.imshow(X_train[i], cmap=pyplot.get_cmap('gray'))\n",
    "# show the figure\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ef44e8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importation des modules\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "(X_train,y_train),(X_test,y_test)=fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a412509",
   "metadata": {},
   "source": [
    "# 3.2.2 Preprocessing Data <br>\n",
    "\n",
    "Before writing neural networks correctly, preprocess the data so that the data complies \n",
    "with the input and output formats of the neural networks. <br>\n",
    "Step 1 Perform one_hot processing.\n",
    "Perform one_hot processing on the <b>Target</b> data (results) of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "748007a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "125737ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "y_cat_train=to_categorical(y_train)\n",
    "y_cat_test=to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "54967ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train/255\n",
    "X_test=X_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d2dbda80",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train.reshape(60000,28,28,1)\n",
    "X_test=X_test.reshape(10000,28,28,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7772fc",
   "metadata": {},
   "source": [
    "## 3.2.3 Building a Neural Network <br>\n",
    "Step 1 Define an input layer. <br>\n",
    "Specify the number of neurons at the input layer. However, because the data is loaded in \n",
    "the matrix format at the beginning, the input layer is represented in the matrix format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0e87617b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Conv2D,MaxPooling2D,Flatten\n",
    "\n",
    "model=Sequential()\n",
    "model.add(Conv2D(filters=32,kernel_size=(3,3),strides=(1,1),input_shape=(28,28,1),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(1,1)))\n",
    "model.add(Conv2D(filters=64,kernel_size=(3,3),strides=(1,1),input_shape=(28,28,1),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(1,1)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dense(10,activation='softmax'))\n",
    "model.compile(loss=\"binary_crossentropy\",optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "016a6059",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early=EarlyStopping(monitor=\"val_loss\",patience=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59470f1b",
   "metadata": {},
   "source": [
    "Step 7 View the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "640b3cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 26, 26, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 24, 24, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 24, 24, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 36864)             0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 128)               4718720   \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,738,826\n",
      "Trainable params: 4,738,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15548f26",
   "metadata": {},
   "source": [
    "Step 8 Train the model.\n",
    "Perform ten rounds of training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "96a0a0d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1000\n",
      "60000/60000 [==============================] - ETA: 0s - loss: 0.0687"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\keras\\engine\\training_v1.py:2045: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 133s 2ms/sample - loss: 0.0687 - val_loss: 0.0579\n",
      "Epoch 2/1000\n",
      "60000/60000 [==============================] - 124s 2ms/sample - loss: 0.0427 - val_loss: 0.0482\n",
      "Epoch 3/1000\n",
      "60000/60000 [==============================] - 119s 2ms/sample - loss: 0.0321 - val_loss: 0.0461\n",
      "Epoch 4/1000\n",
      "60000/60000 [==============================] - 120s 2ms/sample - loss: 0.0231 - val_loss: 0.0486\n",
      "Epoch 5/1000\n",
      "60000/60000 [==============================] - 121s 2ms/sample - loss: 0.0160 - val_loss: 0.0555\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24409218d60>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_cat_train,validation_data=(X_test,y_cat_test),epochs=1000,callbacks=[early])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9958372",
   "metadata": {},
   "source": [
    "Step 9 Evaluate the model by using the test set. <br>\n",
    "Perform prediction evaluation by using the test set to determine whether the model is \n",
    "appropriate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ba54e763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses=pd.DataFrame(model.history.history)\n",
    "losses.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d90e45f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\keras\\engine\\training_v1.py:2067: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1, ..., 8, 1, 5], dtype=int64)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions=np.argmax(model.predict(X_test),axis=1)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "24849568",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0d82a052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.89      0.86      1000\n",
      "           1       1.00      0.98      0.99      1000\n",
      "           2       0.85      0.89      0.87      1000\n",
      "           3       0.93      0.92      0.92      1000\n",
      "           4       0.86      0.85      0.86      1000\n",
      "           5       0.99      0.97      0.98      1000\n",
      "           6       0.79      0.75      0.77      1000\n",
      "           7       0.95      0.97      0.96      1000\n",
      "           8       0.99      0.98      0.98      1000\n",
      "           9       0.97      0.97      0.97      1000\n",
      "\n",
      "    accuracy                           0.92     10000\n",
      "   macro avg       0.92      0.92      0.92     10000\n",
      "weighted avg       0.92      0.92      0.92     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d697c450",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat = confusion_matrix(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6301f517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[888   1  15   9   4   1  78   0   4   0]\n",
      " [  3 981   0   7   4   0   4   0   1   0]\n",
      " [ 19   1 885   5  40   0  49   0   1   0]\n",
      " [ 18   2  15 915  30   0  19   0   0   1]\n",
      " [  5   0  75  19 855   1  45   0   0   0]\n",
      " [  0   0   0   1   0 975   0  17   0   7]\n",
      " [120   0  47  21  59   0 747   0   6   0]\n",
      " [  0   0   0   0   0   1   0 975   0  24]\n",
      " [  1   0   3   6   3   1   4   2 980   0]\n",
      " [  1   0   0   0   0   4   0  28   0 967]]\n"
     ]
    }
   ],
   "source": [
    "print(conf_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead38712",
   "metadata": {},
   "source": [
    "Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c5fb5600",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"modelFashionMNIST-DanielMrnth.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
